# 交互记录

## 1. 创建 CLAUDE.md 文件

### 提问
请分析这个代码库并创建一个 CLAUDE.md 文件,用于指导未来的 Claude Code 实例在此仓库中工作。

### 回答
已成功分析 TienKung-Lab 代码库并创建了 `/home/ykj/project/TienKung-Lab/CLAUDE.md` 文件。

该文件包含以下内容:

1. **项目概述**
   - TienKung-Lab 是基于 IsaacLab 的全尺寸人形机器人强化学习运动控制框架
   - 技术栈: IsaacSim 4.5.0, IsaacLab 2.1.0, RSL_RL 2.3.1, Python 3.10, MuJoCo 3.3.2

2. **常用命令**
   - 安装与设置命令
   - 训练命令 (walk/run 任务)
   - 测试与可视化命令 (带/不带传感器)
   - Sim2Sim 验证命令
   - TensorBoard 和代码格式化命令

3. **架构设计**
   - 核心组件层次结构:
     - 任务注册系统 (`task_registry.py`)
     - 基础环境架构 (`BaseEnv`, `BaseEnvCfg`)
     - TienKung 环境实现 (walk/run 配置)
     - 奖励与感知系统 (MDP 奖励、相机、激光雷达)
     - RSL-RL 算法 (PPO, AMP-PPO)

   - 动作重定向工作流:
     - 数据集结构 (`motion_visualization/`, `motion_amp_expert/`)
     - 数据转换流程 (GMR → 可视化数据 → 专家数据)

   - 关键配置参数:
     - 步态参数 (周期、离地比例、相位偏移)
     - 奖励权重
     - 仿真参数 (physics_dt: 0.005s, control freq: 50Hz)

   - 导出与部署:
     - 自动导出 JIT 和 ONNX 格式
     - 包含观察归一化器

   - 与 IsaacLab 的集成方式

4. **开发注意事项**
   - 带传感器任务的自动相机渲染
   - 策略自动导出机制
   - 日志路径结构
   - Conda 环境使用建议

文件位置: `/home/ykj/project/TienKung-Lab/CLAUDE.md`

## 2. G1 重定向效果不佳的问题排查与解决

### 提问
现在用的 g1 重定向显示出来的效果不好,现在在排查原因,我觉得可能是因为在 gmr 中我用的是 g1_mocap_29dof.xml 而在这里我用的是 g1_29dof.xml 的原因,但是 gmr 中没有 mocap 版本 xml 的 urdf 文件,这个项目在哪里要用到 urdf 文件,能不能改为使用 mocap 版本的 xml 进行 Motion Visualization 这一步,调试到可以正常执行并显示可视化界面让我检查重定向结果,用 dance1_2.txt 来可视化。

### 回答

#### 问题分析
1. **IsaacLab 使用的是 USD 文件,不是 XML**
   - 在 `legged_lab/assets/g1_29dof/g1_29dof.py:36` 中,项目使用 `g1_29dof.usd` 文件
   - XML 文件 (`g1_29dof.xml` 和 `g1_mocap_29dof.xml`) 是为 MuJoCo/GMR 准备的,不在 IsaacLab 中使用

2. **g1_29dof.xml 和 g1_mocap_29dof.xml 的主要差异**
   - **关节范围限制不同**: mocap 版本的关节范围更受限(如 hip_pitch 从 [-2.5307, 2.8798] 改为 [-1.57, 1.57])
   - **模型命名**: `g1_29dof` vs `g1_mocap`
   - **网格文件名**: 某些 link 使用了 `_rev_1_0` 后缀的网格文件
   - **额外的 body**: mocap 版本添加了 `left_toe_link` 和 `pelvis_contour_link`
   - **关节类型**: `floating_base_joint` (type="free") vs `pelvis` (freejoint)

3. **dance1_2.txt 文件位置**
   - 原始位置: `legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt`
   - 需要复制到: `legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt`

#### 解决方案

**步骤 1: 复制 dance1_2.txt 到 G1 数据集目录**
```bash
mkdir -p legged_lab/envs/g1/datasets/motion_visualization
cp legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt \
   legged_lab/envs/g1/datasets/motion_visualization/
```

**步骤 2: 修改 G1 环境配置**
已修改以下文件使用 dance1_2.txt:
- `legged_lab/envs/g1/g1_walk_cfg.py:164`
- `legged_lab/envs/g1/g1_run_cfg.py:164`

修改内容:
```python
amp_motion_files_display = ["legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt"]
```

**步骤 3: 验证配置**
运行测试脚本 `test_g1_dance_config.py` 确认:
- ✅ dance1_2.txt 文件存在
- ✅ JSON 格式正确
- ✅ 包含 3944 帧数据
- ✅ 每帧 70 维数据
- ✅ 两个配置文件都已更新

**步骤 4: 运行可视化**
使用以下命令运行 G1 动作可视化:
```bash
# 方式 1: 使用 IsaacLab 脚本 (推荐)
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1

# 方式 2: 直接使用 Python (需要设置环境变量)
LD_LIBRARY_PATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni:$LD_LIBRARY_PATH \
PYTHONPATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni/kernel/py:$PYTHONPATH \
conda run -n TieKung python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1

# 方式 3: 使用 g1_run 任务
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_run --num_envs=1
```

#### 重要发现

1. **XML vs USD 的区别**
   - IsaacSim/IsaacLab 使用 USD (Universal Scene Description) 格式
   - GMR 使用 MuJoCo XML 格式
   - 两者的差异不会影响 IsaacLab 的可视化,因为 IsaacLab 不读取 XML 文件

2. **动作数据格式**
   - `gmr_data_conversion.py` 将 GMR 输出的 PKL 文件转换为项目所需的 TXT 格式
   - 格式包含: `[root_pos(3), euler_angles(3), dof_pos(26), root_lin_vel(3), root_ang_vel(3), dof_vel(26)]`
   - G1 29DOF: 26 个可控关节 (6 腿部 × 2 + 3 腰部 + 4 手臂 × 2 + 3 手腕 × 2)

3. **可视化流程**
   - `play_amp_animation.py` 使用 `AMPLoaderDisplay` 加载 TXT 文件
   - `G1Env.visualize_motion()` 方法根据时间戳设置机器人状态
   - 数据映射: 从 TXT 格式的 dof_pos/vel 映射到 G1 的特定关节顺序

#### 下一步建议

1. **检查重定向质量**
   - 在 IsaacSim 可视化界面中观察 dance1_2 动作
   - 检查关节角度是否在合理范围内
   - 观察是否有不自然的姿态或抖动

2. **如果效果仍不理想**
   - 可能需要调整 GMR 的重定向参数
   - 检查 G1 的关节限制是否与 mocap 版本一致
   - 考虑在 `g1_29dof.py` 中调整关节范围限制

3. **生成 AMP 训练数据**
   ```bash
   /home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
       --task=g1_walk --num_envs=1 \
       --save_path legged_lab/envs/g1/datasets/motion_amp_expert/dance1_2.txt
   ```

#### 相关文件位置
- G1 USD 配置: `legged_lab/assets/g1_29dof/g1_29dof.py:36`
- G1 环境类: `legged_lab/envs/g1/g1_env.py`
- 可视化脚本: `legged_lab/scripts/play_amp_animation.py`
- 数据转换脚本: `legged_lab/scripts/gmr_data_conversion.py`
- Walk 配置: `legged_lab/envs/g1/g1_walk_cfg.py:164`
- Run 配置: `legged_lab/envs/g1/g1_run_cfg.py:164`

---

## 3. visualize_motion 实现原理

### 提问
visualize_motion这一步是怎么实现的,怎么读取的数据然后用的哪里的机器人配置文件进行可视化

### 回答

#### 整体工作流程

`visualize_motion` 是一个用于在 IsaacSim 中播放动作捕捉数据的可视化系统,主要分为以下几个步骤:

**1. 数据加载阶段 (初始化时)**

在环境初始化时 (`legged_lab/envs/tienkung/tienkung_env.py:123-126`):
```python
self.amp_loader_display = AMPLoaderDisplay(
    motion_files=self.cfg.amp_motion_files_display,
    device=self.device,
    time_between_frames=self.physics_dt
)
self.motion_len = self.amp_loader_display.trajectory_num_frames[0]
```

**2. 数据文件配置**

动作数据文件在各个任务配置中定义,例如在 `legged_lab/envs/tienkung/walk_cfg.py:164`:
```python
amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
```

**3. 数据读取与解析** (`rsl_rl/rsl_rl/utils/motion_loader_for_display.py`)

`AMPLoaderDisplay` 类负责读取和解析动作数据:
- **文件格式**: JSON 格式的 TXT 文件,包含:
  - `LoopMode`: 循环模式 ("Wrap")
  - `FrameDuration`: 帧间隔时间 (通常 1/30 秒)
  - `EnableCycleOffsetPosition/Rotation`: 循环偏移设置
  - `MotionWeight`: 动作权重
  - `Frames`: 动作帧数组

- **数据结构** (motion_loader_for_display.py:68-79):
  ```python
  motion_data = np.array(motion_json["Frames"])
  # 提取关节位置和速度数据 (前52维)
  self.trajectories_full.append(
      torch.tensor(motion_data[:, :AMPLoaderDisplay.JOINT_VEL_END_IDX], ...)
  )
  ```

- **数据维度**:
  - `JOINT_POS_SIZE = 26`: 关节位置维度
  - `JOINT_VEL_SIZE = 26`: 关节速度维度
  - 总共 52 维 (26 位置 + 26 速度)

**4. 可视化执行** (`legged_lab/scripts/play_amp_animation.py:54-87`)

主循环调用 `visualize_motion`:
```python
while simulation_app.is_running():
    while True:
        time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
        frame = env.visualize_motion(time)  # 核心调用
        frame_cnt += 1
        if frame_cnt >= (env.motion_len - 1):
            break
    break
```

**5. visualize_motion 方法详解** (`legged_lab/envs/tienkung/tienkung_env.py:248-352`)

核心实现步骤:

**(1) 获取指定时间的动作帧** (248-262行):
```python
visual_motion_frame = self.amp_loader_display.get_full_frame_at_time(0, time)
```
- `get_full_frame_at_time` 方法通过线性插值获取精确时刻的动作数据
- 数据格式: `[root_pos(3), euler(3), dof_pos(26), root_lin_vel(3), ang_vel(3), dof_vel(26)]`

**(2) 映射关节数据到机器人** (265-276行):
```python
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # 左腿 6DOF
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # 右腿 6DOF
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]   # 左臂 4DOF
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26]  # 右臂 4DOF
# 速度同理映射
```

**(3) 写入机器人状态** (278-302行):
```python
# 写入关节位置和速度
self.robot.write_joint_position_to_sim(dof_pos)
self.robot.write_joint_velocity_to_sim(dof_vel)

# 处理 Root 状态 (位置、姿态、速度)
root_pos = visual_motion_frame[:3].clone()
root_pos[2] += 0.3  # Z轴偏移

# Euler 角转四元数
euler = visual_motion_frame[3:6].cpu().numpy()
quat_xyzw = Rotation.from_euler("XYZ", euler, degrees=False).as_quat()
quat_wxyz = torch.tensor([quat_xyzw[3], quat_xyzw[0], quat_xyzw[1], quat_xyzw[2]], ...)

# 构建完整 root_state: [x,y,z, qw,qx,qy,qz, vx,vy,vz, wx,wy,wz]
self.robot.write_root_state_to_sim(root_state, env_ids)
```

**(4) 仿真更新** (303-305行):
```python
self.sim.render()
self.sim.step()
self.scene.update(dt=self.step_dt)
```

**(5) 计算末端执行器位置** (307-326行):
```python
# 计算左右手位置 (相对 root 的局部坐标)
left_hand_pos = self.robot.data.body_state_w[:, self.elbow_body_ids[0], :3] - ...
# 转换到 root 局部坐标系
left_hand_pos = quat_apply(quat_conjugate(self.robot.data.root_state_w[:, 3:7]), left_hand_pos)
# 同理计算脚部位置
```

**(6) 返回完整状态** (336-352行):
```python
return torch.cat((
    self.right_arm_dof_pos,   # 右臂关节位置
    self.left_arm_dof_pos,    # 左臂关节位置
    self.right_leg_dof_pos,   # 右腿关节位置
    self.left_leg_dof_pos,    # 左腿关节位置
    self.right_arm_dof_vel,   # 速度同理...
    self.left_arm_dof_vel,
    self.right_leg_dof_vel,
    self.left_leg_dof_vel,
    left_hand_pos,            # 左手位置
    right_hand_pos,           # 右手位置
    left_foot_pos,            # 左脚位置
    right_foot_pos            # 右脚位置
), dim=-1)
```

#### 机器人配置文件

**1. 主要配置文件路径**:

- **USD 模型文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
  - 在 `legged_lab/assets/tienkung2_lite/tienkung.py:36` 中引用

- **关节配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
  ```python
  TIENKUNG2LITE_CFG = ArticulationCfg(
      spawn=sim_utils.UsdFileCfg(
          usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
          ...
      ),
      init_state=ArticulationCfg.InitialStateCfg(
          pos=(0.0, 0.0, 1.0),
          joint_pos={...},  # 初始关节位置
          joint_vel={".*": 0.0},
      ),
      actuators={
          "legs": ImplicitActuatorCfg(...),   # 腿部执行器配置
          "feet": ImplicitActuatorCfg(...),   # 脚部执行器配置
          "arms": ImplicitActuatorCfg(...),   # 手臂执行器配置
      },
  )
  ```

- **环境配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
  ```python
  class TienKungWalkFlatEnvCfg:
      amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
      scene: BaseSceneCfg = BaseSceneCfg(
          robot=TIENKUNG2LITE_CFG,  # 使用上述机器人配置
          terrain_type="generator",
          ...
      )
  ```

**2. 关节 ID 映射** (`legged_lab/envs/tienkung/tienkung_env.py:163-212`):

系统在初始化时通过 `find_joints` 方法获取关节索引:
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=["hip_roll_l_joint", "hip_pitch_l_joint", "hip_yaw_l_joint",
               "knee_pitch_l_joint", "ankle_pitch_l_joint", "ankle_roll_l_joint"],
    preserve_order=True,
)
# 同理获取 right_leg_ids, left_arm_ids, right_arm_ids, ankle_joint_ids 等
```

**3. Body ID 映射** (163-168行):
```python
self.feet_body_ids, _ = self.robot.find_bodies(
    name_keys=["ankle_roll_l_link", "ankle_roll_r_link"],
    preserve_order=True
)
self.elbow_body_ids, _ = self.robot.find_bodies(
    name_keys=["elbow_pitch_l_link", "elbow_pitch_r_link"],
    preserve_order=True
)
```

#### 数据流总结

```
1. TXT文件 (JSON格式)
   ↓ (AMPLoaderDisplay 读取)
2. Torch Tensor [N_frames, 52]
   ↓ (get_full_frame_at_time 插值)
3. 单帧数据 [root(6) + dof_pos(26) + root_vel(6) + dof_vel(26)]
   ↓ (visualize_motion 映射)
4. 机器人状态
   - dof_pos/vel → 按 joint_ids 映射到具体关节
   - root state → 写入机器人根部状态
   ↓ (IsaacSim 仿真)
5. 可视化显示 + 末端执行器位置计算
```

#### 关键文件位置汇总

- **可视化脚本**: `legged_lab/scripts/play_amp_animation.py:54-118`
- **环境实现**: `legged_lab/envs/tienkung/tienkung_env.py:248-352`
- **数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py:26-283`
- **机器人配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
- **任务配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
- **USD 模型**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`

#### 注意事项

1. **坐标系转换**:
   - Root 姿态使用欧拉角 (XYZ) 转四元数 (WXYZ)
   - 末端位置从世界坐标转换到 Root 局部坐标

2. **数据格式要求**:
   - 必须是 JSON 格式 TXT 文件
   - 包含 `FrameDuration`, `Frames` 等关键字段
   - 每帧数据至少 52 维 (26 pos + 26 vel)

3. **机器人配置一致性**:
   - USD 文件定义物理模型和视觉外观
   - ArticulationCfg 定义执行器参数
   - 关节顺序必须与数据文件匹配

---

## 4. USD 文件详解

### 提问
usd文件是什么

### 回答

#### 📚 基本概念

**USD** (Universal Scene Description,通用场景描述) 是由 **Pixar** 开发的一种开源框架和文件格式,用于描述、组合和模拟复杂的 3D 场景。

**核心特点**:
1. **通用性**: 描述完整的 3D 场景(几何、材质、灯光、相机、动画等)
2. **可组合性**: 支持场景分层和引用,可将多个 USD 文件组合
3. **高性能**: 针对大规模场景优化,支持延迟加载
4. **可扩展**: 支持自定义数据类型和属性
5. **行业标准**: 广泛应用于电影、游戏、机器人仿真等领域

#### 📁 USD 文件格式类型

| 扩展名 | 格式 | 特点 | 用途 |
|--------|------|------|------|
| `.usd` | 通用格式 | 可以是文本或二进制 | 一般用途 |
| `.usda` | ASCII 文本 | 人类可读,易于版本控制 | 调试、手动编辑 |
| `.usdc` | 二进制 Crate | 紧凑高效,加载快 | 生产环境 |
| `.usdz` | 压缩包 | 包含所有依赖资源 | 分发、AR 应用 |

在本项目中,使用的是 **`.usd` 格式**(实际为二进制 USD crate 0.8.0 版本):
```bash
$ file tienkung2_lite.usd
tienkung2_lite.usd: USD crate, version 0.8.0
```

#### 🤖 在机器人仿真中的应用

USD 文件在 IsaacSim/IsaacLab 中定义完整的机器人模型:

**1. 几何结构**:
- Links/Bodies: 机器人的刚体部件
- 网格文件引用: STL、OBJ 等格式的 3D 模型
- 视觉外观: 材质、纹理、颜色

**2. 物理属性**:
- 质量 (Mass)
- 惯性矩阵 (Inertia)
- 碰撞体 (Colliders): 凸包、网格、基本形状
- 摩擦系数、恢复系数

**3. 关节定义**:
- 关节类型: Revolute(旋转)、Prismatic(平移)、Fixed(固定)
- 关节轴向
- 关节限制 (位置、速度、力矩)
- 驱动参数 (刚度、阻尼)

**4. 传感器与附件**:
- 相机 (RGB、深度、分割)
- 激光雷达
- IMU、接触传感器等

#### 🔄 与其他格式的对比

| 格式 | 开发者 | 主要用途 | 优点 | 缺点 |
|------|--------|---------|------|------|
| **URDF** | ROS 社区 | ROS 机器人 | 简单易用,ROS 生态 | 功能有限,不支持复杂场景 |
| **MJCF/XML** | DeepMind | MuJoCo 仿真 | 物理仿真精确 | 专用格式,不通用 |
| **USD** | Pixar | 通用场景描述 | 功能强大,行业标准 | 学习曲线较陡 |
| **SDF** | OSRF | Gazebo 仿真 | 类似 URDF,功能更强 | 主要限于 Gazebo |

#### 📂 在 TienKung-Lab 项目中的使用

**项目中的 USD 文件结构**:
```
legged_lab/assets/tienkung2_lite/
├── usd/
│   ├── tienkung2_lite.usd              # 主 USD 文件
│   ├── config.yaml                      # USD 转换配置
│   ├── configuration/
│   │   ├── tienkung2_lite_base.usd     # 基础几何和物理
│   │   ├── tienkung2_lite_physics.usd  # 物理属性
│   │   └── tienkung2_lite_sensor.usd   # 传感器配置
│   └── .asset_hash                      # 资产哈希值
├── urdf/
│   └── tienkung2_lite.urdf             # 源 URDF 文件
├── mjcf/
│   └── tienkung.xml                     # MuJoCo XML (用于 Sim2Sim)
├── meshes/                              # 3D 网格文件
│   ├── pelvis.STL
│   ├── hip_roll_l_link.STL
│   ├── knee_pitch_l_link.STL
│   └── ... (其他 STL 文件)
└── tienkung.py                          # IsaacLab 配置文件
```

**USD 文件的层次结构**:

主文件 `tienkung2_lite.usd` 通过 **subLayers** 引用其他配置文件:
```
tienkung2_lite.usd
├── configuration/tienkung2_lite_base.usd     (几何和结构)
├── configuration/tienkung2_lite_physics.usd  (物理属性)
└── configuration/tienkung2_lite_sensor.usd   (传感器)
```

这种分层设计的优势:
- **模块化**: 不同配置分离,易于维护
- **可复用**: 可在不同场景中复用基础模型
- **版本控制**: 可单独修改物理或传感器配置

#### 🔧 USD 文件的生成

在本项目中,USD 文件是从 URDF 转换而来,配置文件 `config.yaml` 记录了转换参数:

```yaml
# 源文件
asset_path: /legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf

# 输出配置
usd_dir: /legged_lab/assets/tienkung2_lite/usd
usd_file_name: tienkung2_lite.usd
force_usd_conversion: true

# 转换选项
make_instanceable: true          # 使模型可实例化(多环境复用)
fix_base: false                  # 不固定基座(人形机器人需要自由移动)
merge_fixed_joints: true         # 合并固定关节
link_density: 0.0                # 链接密度(0表示使用URDF中的质量)

# 关节驱动配置
joint_drive:
  drive_type: force              # 力控制
  target_type: none              # 无默认目标
  gains:
    stiffness: 0.0               # 刚度(在Python配置中单独设置)
    damping: 0.0                 # 阻尼(在Python配置中单独设置)

# 碰撞配置
collider_type: convex_hull       # 使用凸包作为碰撞体
self_collision: false            # 禁用自碰撞
collision_from_visuals: false    # 不从视觉网格生成碰撞体
replace_cylinders_with_capsules: false
```

**转换工具**: IsaacSim 提供的 URDF Importer (在配置中记录为 `UrdfConverter`)

#### 🎮 USD 文件在代码中的使用

在 `legged_lab/assets/tienkung2_lite/tienkung.py:34-50`:

```python
TIENKUNG2LITE_CFG = ArticulationCfg(
    spawn=sim_utils.UsdFileCfg(
        usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
        activate_contact_sensors=True,
        rigid_props=sim_utils.RigidBodyPropertiesCfg(
            disable_gravity=False,
            max_linear_velocity=1000.0,
            max_angular_velocity=1000.0,
            ...
        ),
        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
            enabled_self_collisions=False,
            solver_position_iteration_count=8,
            solver_velocity_iteration_count=4
        ),
    ),
    ...
)
```

**关键参数说明**:
- `usd_path`: USD 文件路径
- `activate_contact_sensors`: 激活接触传感器
- `rigid_props`: 刚体物理属性(重力、速度限制等)
- `articulation_props`: 关节树属性(碰撞、求解器迭代次数)

#### 🔍 查看和编辑 USD 文件

**1. 使用 USD 工具**:
```bash
# 查看 USD 文件信息
usdcat tienkung2_lite.usd

# 转换为文本格式
usdcat tienkung2_lite.usd -o tienkung2_lite.usda

# 查看 USD 层次结构
usdtree tienkung2_lite.usd
```

**2. 使用 IsaacSim**:
- 在 IsaacSim GUI 中直接打开 USD 文件
- 可视化查看机器人模型
- 检查关节、碰撞体、物理属性

**3. 使用 USD Composer (原 Omniverse Create)**:
- Nvidia 提供的 USD 编辑器
- 可视化编辑场景、材质、物理属性

#### 🌟 USD 的优势总结

在机器人仿真中使用 USD 的优势:

1. **统一标准**: Pixar、Nvidia、Apple 等公司共同支持
2. **高性能**: 针对大规模场景优化,支持 GPU 加速
3. **场景组合**: 可以轻松组合多个机器人、环境、道具
4. **物理仿真**: 与 PhysX 等物理引擎深度集成
5. **实时渲染**: 支持光线追踪、实时渲染
6. **数据管道**: 适合从设计到仿真再到部署的完整流程

#### 相关资源

- **USD 官方文档**: https://openusd.org/
- **IsaacSim USD 文档**: https://docs.omniverse.nvidia.com/isaacsim/latest/
- **USD Python API**: `pxr` 包 (Pixar USD Python 绑定)
- **转换工具**: IsaacSim URDF Importer, USD Composer

#### 关键文件位置

- **主 USD 文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
- **转换配置**: `legged_lab/assets/tienkung2_lite/usd/config.yaml`
- **Python 配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:36`
- **源 URDF**: `legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf`
- **网格文件**: `legged_lab/assets/tienkung2_lite/meshes/*.STL`

---

## 5. play_amp_animation 的 save_path 参数详解

### 提问
play_amp_animation的save_path时要保存什么,这里保存和task以及机器人的配置文件有关吗

### 回答

#### 保存的数据内容

`play_amp_animation.py` 的 `--save_path` 参数用于保存 **AMP 专家数据**,这些数据将用于 AMP (Adversarial Motion Priors) 训练。

**数据维度组成 (共 52 维)**:

根据 `legged_lab/envs/tienkung/tienkung_env.py:336-352`,保存的数据包含:

1. **右臂关节位置** (4维): `right_arm_dof_pos`
2. **左臂关节位置** (4维): `left_arm_dof_pos`
3. **右腿关节位置** (6维): `right_leg_dof_pos`
4. **左腿关节位置** (6维): `left_leg_dof_pos`
5. **右臂关节速度** (4维): `right_arm_dof_vel`
6. **左臂关节速度** (4维): `left_arm_dof_vel`
7. **右腿关节速度** (6维): `right_leg_dof_vel`
8. **左腿关节速度** (6维): `left_leg_dof_vel`
9. **左手位置** (3维): `left_hand_pos` (相对 root 的局部坐标)
10. **右手位置** (3维): `right_hand_pos` (相对 root 的局部坐标)
11. **左脚位置** (3维): `left_foot_pos` (相对 root 的局部坐标)
12. **右脚位置** (3维): `right_foot_pos` (相对 root 的局部坐标)

**数据格式** (由 `legged_lab/scripts/play_amp_animation.py:89-113` 生成):
```json
{
"LoopMode": "Wrap",
"FrameDuration": 0.033,  // 由 --fps 参数决定 (1/fps)
"EnableCycleOffsetPosition": true,
"EnableCycleOffsetRotation": true,
"MotionWeight": 0.5,

"Frames":
[
  [关节位置(20维), 关节速度(20维), 末端位置(12维)],  // 第1帧,共52维
  [关节位置(20维), 关节速度(20维), 末端位置(12维)],  // 第2帧
  ...
]
}
```

#### 与 task 和机器人配置的关系

**是的,保存的数据与 task 和机器人配置高度相关:**

##### 1. 机器人配置文件的影响

保存的数据结构由机器人配置决定 (`legged_lab/envs/tienkung/tienkung_env.py:163-212`):

**关节映射**:
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=["hip_roll_l_joint", "hip_pitch_l_joint", "hip_yaw_l_joint",
               "knee_pitch_l_joint", "ankle_pitch_l_joint", "ankle_roll_l_joint"],
    preserve_order=True,
)
# 同理: right_leg_ids (6), left_arm_ids (4), right_arm_ids (4)
```

**Body 映射**:
```python
self.feet_body_ids, _ = self.robot.find_bodies(
    name_keys=["ankle_roll_l_link", "ankle_roll_r_link"],
    preserve_order=True
)
self.elbow_body_ids, _ = self.robot.find_bodies(
    name_keys=["elbow_pitch_l_link", "elbow_pitch_r_link"],
    preserve_order=True
)
```

**机器人模型**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
- 定义机器人的物理结构、关节名称、Body 名称
- 不同机器人的关节数量和名称不同,导致输出数据维度不同

##### 2. Task 配置的影响

**输入数据路径**在 task 配置中指定:

- **Walk Task** (`legged_lab/envs/tienkung/walk_cfg.py:164`):
  ```python
  amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/cmu_2_2_1.txt"]
  ```

- **Run Task** (`legged_lab/envs/tienkung/run_cfg.py:164`):
  ```python
  amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/run.txt"]
  ```

##### 3. 数据类型对比

**重要**: 输入的 `motion_visualization` 数据格式与输出的 AMP 专家数据格式不同:

| 数据类型 | 路径 | 维度 | 内容 |
|---------|------|------|------|
| **可视化数据** (输入) | `datasets/motion_visualization/` | 约 70 维 | `[root_pos(3), euler(3), dof_pos(26), root_lin_vel(3), root_ang_vel(3), dof_vel(26), ...]` |
| **AMP 专家数据** (输出) | `datasets/motion_amp_expert/` | 52 维 | `[dof_pos(20), dof_vel(20), end_effector_pos(12)]` |

**数据转换流程**:
```
GMR 重定向输出 (PKL)
    ↓ (gmr_data_conversion.py)
motion_visualization 数据 (TXT)  ← 包含 root 状态和完整关节信息
    ↓ (play_amp_animation.py --save_path)
motion_amp_expert 数据 (TXT)     ← 仅包含关节和末端位置,用于 AMP 训练
```

#### 使用示例

**为 TienKung 机器人生成 AMP 专家数据**:

```bash
# 从可视化数据生成 AMP 专家数据
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=walk \
    --num_envs=1 \
    --save_path legged_lab/envs/tienkung/datasets/motion_amp_expert/cmu_2_2_1.txt \
    --fps 30.0

# 查看生成的数据维度
grep "\[" legged_lab/envs/tienkung/datasets/motion_amp_expert/cmu_2_2_1.txt | head -1 | tr ',' '\n' | wc -l
# 输出应该是 52
```

**为 G1 机器人生成 AMP 专家数据** (如果机器人结构不同,输出维度可能不同):

```bash
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk \
    --num_envs=1 \
    --save_path legged_lab/envs/g1/datasets/motion_amp_expert/dance1_2.txt \
    --fps 30.0
```

#### 关键特性总结

1. **机器人特定性**:
   - 不同机器人的 AMP 数据**不能通用**
   - 关节数量、顺序、名称不同导致数据维度不同
   - Body 名称和 ID 不同影响末端位置计算

2. **输入数据要求**:
   - 必须先有对应的 `motion_visualization` 数据
   - 在配置文件中正确设置 `amp_motion_files_display` 路径

3. **数据用途**:
   - 保存的 AMP 专家数据用于训练时的判别器
   - 判别器比较策略生成的动作和专家数据的相似度
   - 在配置文件中通过 `amp_motion_files` 参数指定 (注意与 `amp_motion_files_display` 不同)

4. **FPS 参数**:
   - `--fps` 参数控制 `FrameDuration` (帧间隔时间)
   - 默认 30 FPS → FrameDuration = 0.033 秒
   - 影响动作的时间分辨率

#### 相关文件位置

- **保存逻辑**: `legged_lab/scripts/play_amp_animation.py:81-115`
- **数据生成方法**: `legged_lab/envs/tienkung/tienkung_env.py:248-352` (visualize_motion)
- **关节映射初始化**: `legged_lab/envs/tienkung/tienkung_env.py:169-212`
- **机器人配置**: `legged_lab/assets/tienkung2_lite/tienkung.py`
- **Task 配置 (输入数据)**: `legged_lab/envs/tienkung/walk_cfg.py:164` (amp_motion_files_display)
- **AMP 数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py`

---

## 6. G1 机器人关节顺序映射问题修复

### 提问
g1的重定向是没问题的,但是用play_amp_animation可视化出来是不对的,感觉是没对上,是不是哪里关节顺序不对,比如dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]这几行里的visual_motion_frame是怎么得到的,是不是g1的这里和tienkung的不一样

### 回答

#### 问题分析

经过仔细排查,发现问题出在 **G1 机器人的关节定义顺序与 GMR 输出的关节顺序不匹配**。

**关键差异**:

1. **GMR 输出的关节顺序** (来自 MuJoCo XML `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`):
   ```
   左腿 (索引 0-5):
   [0] left_hip_pitch_joint    ← pitch 在前
   [1] left_hip_roll_joint
   [2] left_hip_yaw_joint
   [3] left_knee_joint
   [4] left_ankle_pitch_joint
   [5] left_ankle_roll_joint

   右腿 (索引 6-11):
   [6] right_hip_pitch_joint   ← pitch 在前
   [7] right_hip_roll_joint
   [8] right_hip_yaw_joint
   [9] right_knee_joint
   [10] right_ankle_pitch_joint
   [11] right_ankle_roll_joint
   ```

2. **G1 环境原始定义** (`legged_lab/envs/g1/g1_env.py:158-179`):
   ```python
   self.left_leg_ids = [
       "left_hip_roll_joint",     ← roll 在前 (与 GMR 不同!)
       "left_hip_pitch_joint",
       "left_hip_yaw_joint",
       "left_knee_joint",
       "left_ankle_pitch_joint",
       "left_ankle_roll_joint",
   ]
   ```

3. **TienKung 环境定义** (`legged_lab/envs/tienkung/tienkung_env.py:169-179`):
   ```python
   self.left_leg_ids = [
       "hip_roll_l_joint",        ← roll 在前 (与 G1 原始定义一致)
       "hip_pitch_l_joint",
       "hip_yaw_l_joint",
       "knee_pitch_l_joint",
       "ankle_pitch_l_joint",
       "ankle_roll_l_joint",
   ]
   ```

**问题根源**:
- GMR 重定向工具按照 MuJoCo XML 中的树形结构顺序输出关节数据 (hip_pitch → hip_roll → hip_yaw)
- G1 环境代码按照字母顺序定义关节 (hip_roll → hip_pitch → hip_yaw)
- 在 `visualize_motion` 中直接映射 `visual_motion_frame[6:12]` 到 `self.left_leg_ids`,导致 pitch 和 roll 关节数据错位

**为什么 TienKung 没问题**:
- TienKung 使用的是自己的 URDF/XML,没有使用 GMR 的 G1 配置
- 或者 TienKung 的 GMR 配置关节顺序正好与环境代码一致

#### 解决方案

修改 `legged_lab/envs/g1/g1_env.py:158-179`,将关节定义顺序改为与 GMR 输出一致:

**修改内容** (g1_env.py:158-179):
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=[
        "left_hip_pitch_joint",  # GMR outputs pitch first
        "left_hip_roll_joint",   # 修改: 将 pitch 移到前面
        "left_hip_yaw_joint",
        "left_knee_joint",
        "left_ankle_pitch_joint",
        "left_ankle_roll_joint",
    ],
    preserve_order=True,
)
self.right_leg_ids, _ = self.robot.find_joints(
    name_keys=[
        "right_hip_pitch_joint",  # GMR outputs pitch first
        "right_hip_roll_joint",   # 修改: 将 pitch 移到前面
        "right_hip_yaw_joint",
        "right_knee_joint",
        "right_ankle_pitch_joint",
        "right_ankle_roll_joint",
    ],
    preserve_order=True,
)
```

#### 关键发现

1. **关节顺序的三个来源**:
   - **MuJoCo XML 树结构**: GMR 使用的物理模型,按照父子关系定义
   - **URDF 定义顺序**: IsaacLab 转换时可能保持或重新排序
   - **代码中的 find_joints**: 使用 `preserve_order=True` 保证按照传入顺序返回

2. **数据映射路径**:
   ```
   GMR 重定向 (MuJoCo XML顺序)
       ↓
   PKL 文件 (dof_pos: pitch, roll, yaw, ...)
       ↓ gmr_data_conversion.py (保持顺序)
   motion_visualization TXT (dof_pos[6:12]: pitch, roll, yaw, ...)
       ↓ visualize_motion
   直接映射到 self.left_leg_ids
       ⚠️ 如果顺序不匹配,会导致关节错位!
   ```

3. **验证方法**:
   运行可视化脚本检查修复效果:
   ```bash
   /home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
       --task=g1_walk --num_envs=1
   ```

#### 影响范围

**仅影响 G1 机器人**:
- ✅ TienKung 机器人不受影响 (关节顺序已匹配)
- ⚠️ 如果为 G1 训练了 AMP 策略,需要重新生成专家数据
- ⚠️ 已有的 G1 训练检查点可能需要重新训练

**不需要修改的部分**:
- ✅ `gmr_data_conversion.py` 脚本 (保持原样,按照 GMR 输出顺序)
- ✅ TienKung 环境代码 (已正确匹配)
- ✅ 数据文件 (dance1_2.txt 等)

#### 相关文件位置

- **修改文件**: `legged_lab/envs/g1/g1_env.py:158-179`
- **GMR 关节定义**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`
- **数据转换脚本**: `legged_lab/scripts/gmr_data_conversion.py` (不需要修改)
- **可视化脚本**: `legged_lab/scripts/play_amp_animation.py`
- **诊断脚本**: `legged_lab/scripts/debug_joint_order.py` (新创建,用于排查问题)

---

## 7. G1 手臂关节映射问题修复

### 提问
比之前好很多了但是还是有问题,现在左右手的动作还是明显不对的,是不是顺序或方向还是错的

### 回答

#### 进一步问题分析

经过第一次修复(腿部关节顺序),腿部动作已经正确,但手臂动作仍然不对。排查后发现**更严重的问题**:

**关键发现**: GMR 输出 29 个自由度 (包括腰部和手腕关节),但原始映射代码假设只有 26 个自由度,导致索引完全错位!

#### GMR 完整关节结构 (29 DOF)

```
[0:6]   左腿 (6 DOF): hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[6:12]  右腿 (6 DOF): hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[12:15] 腰部 (3 DOF): waist_yaw, waist_roll, waist_pitch  ← 原映射忽略了!
[15:19] 左臂 (4 DOF): shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19:22] 左手腕 (3 DOF): wrist_roll, wrist_pitch, wrist_yaw  ← 原映射忽略了!
[22:26] 右臂 (4 DOF): shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26:29] 右手腕 (3 DOF): wrist_roll, wrist_pitch, wrist_yaw  ← 原映射忽略了!
```

#### 原始错误映射

```python
# 错误的映射 (假设26 DOF,没有腰部和手腕)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]   # ❌ 实际是右腿数据!
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18] # ❌ 实际是腰部+左臂部分数据!
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]  # ❌ 实际是左手腕+右臂部分!
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26] # ❌ 实际是右臂数据(正确!)
```

这就是为什么:
- 腿部动作完全错乱 (左腿收到右腿数据)
- 左臂收到手腕数据,动作完全不对
- 只有右臂碰巧索引对了

#### visual_motion_frame 完整数据格式 (70 维)

`gmr_data_conversion.py` 输出格式:
```python
data_output = [
    root_pos[:-1],      # [0:3]   根位置
    euler_angles,       # [3:6]   欧拉角
    dof_pos[:-1],       # [6:35]  关节位置 (29 DOF)
    root_lin_vel,       # [35:38] 根线速度
    root_ang_vel,       # [38:41] 根角速度
    dof_vel             # [41:70] 关节速度 (29 DOF)
]
```

#### 正确的映射方案

```python
dof_pos_offset = 6  # skip root_pos(3) + euler(3)

# 位置数据 [6:35] (29 DOF)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # [6:12] 左腿
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # [12:18] 右腿
# [18:21] 跳过腰部 (3 DOF)
dof_pos[:, self.left_arm_ids] = visual_motion_frame[21:25]   # [21:25] 左臂
# [25:28] 跳过左手腕 (3 DOF)
dof_pos[:, self.right_arm_ids] = visual_motion_frame[28:32]  # [28:32] 右臂
# [32:35] 跳过右手腕 (3 DOF)

# 速度数据 [41:70] (29 DOF),同样的偏移
dof_vel_offset = 41  # 或 6 + 29 + 6
dof_vel[:, self.left_leg_ids] = visual_motion_frame[41:47]    # 左腿速度
dof_vel[:, self.right_leg_ids] = visual_motion_frame[47:53]   # 右腿速度
dof_vel[:, self.left_arm_ids] = visual_motion_frame[56:60]    # 左臂速度 (跳过腰部)
dof_vel[:, self.right_arm_ids] = visual_motion_frame[63:67]   # 右臂速度 (跳过左手腕)
```

#### 修改内容

**文件**: `legged_lab/envs/g1/g1_env.py:254-273`

**修改前** (部分错误已在问题6中修复):
```python
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]   # ❌ 错误!
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26]  # ❌ 错误!
```

**修改后**:
```python
# visual_motion_frame format (70 dims):
# [0:3] root_pos, [3:6] euler, [6:35] dof_pos(29), [35:38] root_lin_vel, [38:41] root_ang_vel, [41:70] dof_vel(29)
# GMR outputs 29 DOF: [legs(12) + waist(3) + left_arm(4) + left_wrist(3) + right_arm(4) + right_wrist(3)]
# G1 environment uses 20 DOF: [legs(12) + arms(8)], no waist and wrist joints

dof_pos_offset = 6  # skip root_pos(3) + euler(3)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[dof_pos_offset+0:dof_pos_offset+6]    # [6:12]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[dof_pos_offset+6:dof_pos_offset+12]  # [12:18]
dof_pos[:, self.left_arm_ids] = visual_motion_frame[dof_pos_offset+15:dof_pos_offset+19]  # [21:25] (skip waist)
dof_pos[:, self.right_arm_ids] = visual_motion_frame[dof_pos_offset+22:dof_pos_offset+26] # [28:32] (skip left wrist)

# Velocity data: [41:70] (29 dims)
dof_vel_offset = 41  # 或 6 + 29 + 6
dof_vel[:, self.left_leg_ids] = visual_motion_frame[dof_vel_offset+0:dof_vel_offset+6]    # [41:47]
dof_vel[:, self.right_leg_ids] = visual_motion_frame[dof_vel_offset+6:dof_vel_offset+12]  # [47:53]
dof_vel[:, self.left_arm_ids] = visual_motion_frame[dof_vel_offset+15:dof_vel_offset+19]  # [56:60]
dof_vel[:, self.right_arm_ids] = visual_motion_frame[dof_vel_offset+22:dof_vel_offset+26] # [63:67]
```

#### 关键要点

1. **G1 环境只使用 20 个关节**:
   - 12 个腿部关节
   - 8 个手臂关节 (每臂 4 个: shoulder pitch/roll/yaw + elbow)
   - **不使用**: 腰部 3 个关节,手腕 6 个关节 (左右各 3 个)

2. **GMR 输出包含所有 29 个关节**:
   - 即使环境不使用腰部和手腕,GMR 数据中仍然包含这些关节
   - 映射时必须跳过这些不使用的关节

3. **数据验证**:
   ```bash
   # 检查 dance1_2.txt 维度
   python3 -c "
   import json
   with open('legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt') as f:
       data = json.load(f)
   print(f'Total dims: {len(data[\"Frames\"][0])}')  # 输出: 70
   "
   ```

#### 验证方法

运行可视化检查修复效果:
```bash
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1
```

现在应该能看到:
- ✅ 腿部动作正确 (问题6已修复)
- ✅ 手臂动作正确 (本次修复)
- ✅ 整体动作协调自然

#### 相关文件位置

- **修改文件**: `legged_lab/envs/g1/g1_env.py:254-273` (visualize_motion 方法)
- **关节定义**: `legged_lab/envs/g1/g1_env.py:158-207`
- **数据转换脚本**: `legged_lab/scripts/gmr_data_conversion.py` (确认输出格式)
- **诊断脚本**: `legged_lab/scripts/debug_arm_mapping.py` (新创建)
- **GMR 配置**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`

---

## 8. 在 TienKung-Lab 项目中添加新机器人完整指南

### 提问
现在是正常的,总结一下在这个项目中加一个新的机器人需要做什么,以及有什么需要注意的(如为什么之前动作不对现在对了)

### 回答

已提供完整的新机器人添加指南,包括:

#### 核心内容
1. **完整流程** (5个步骤):
   - 准备模型文件 (URDF → USD)
   - 创建环境类 (关节映射是关键!)
   - 创建任务配置
   - 注册任务
   - 动作重定向数据准备

2. **关键注意事项**:
   - ⚠️ 关节顺序必须与 GMR 输出完全一致
   - ⚠️ 处理不同机器人的 DOF 数量差异
   - ⚠️ 正确跳过不使用的关节(腰部/手腕)

3. **G1 问题根本原因**:
   - **问题 1**: 腿部 pitch/roll 顺序反了
   - **问题 2**: 手臂映射没跳过腰部/手腕关节
   - **问题 3**: 速度数据访问越界(AMPLoaderDisplay 只加载52维)

4. **修复总结**:
   - 修改关节定义顺序匹配 GMR XML
   - 修正数据映射索引,跳过不用关节
   - 将不完整的速度数据设为 0

5. **验证方法**:
   - 创建诊断脚本对比关节顺序
   - 检查数据文件维度
   - 运行可视化验证效果

#### 相关文件位置
- **修改**: `legged_lab/envs/g1/g1_env.py:158-179, 254-283`
- **参考**: GMR XML, 数据转换脚本, AMPLoaderDisplay
- **诊断**: `debug_joint_order.py`, `debug_arm_mapping.py`

---

## 9. play_amp_animation 循环播放动作

### 提问
用 legged_lab/scripts/play_amp_animation.py 机器人只会播放一次动作然后就站着不动了,怎么让他循环或者重新播放,要点哪里呢还是要改代码

### 回答

#### 问题原因

在 `legged_lab/scripts/play_amp_animation.py:77-87` 中,代码存在两个嵌套的 `while` 循环,但外层循环在播放一次动作后立即 `break` 退出,导致机器人只播放一次就停止了。

**原始代码结构** (play_amp_animation.py:77-87):
```python
frame_cnt = 0
all_frames = []
while simulation_app.is_running():    # 外层循环
    while True:                       # 内层循环
        time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
        frame = env.visualize_motion(time)
        if args_cli.save_path:
            frame = frame.cpu().numpy().reshape(-1)
            all_frames.append(frame)
        frame_cnt += 1
        if frame_cnt >= (env.motion_len - 1):
            break                     # 退出内层循环
    break                             # ❌ 退出外层循环,导致只播放一次
```

#### 解决方案

**修改内容** (play_amp_animation.py:77-86):

删除了内层 `while True` 循环和外层的 `break`,简化为单层循环:

```python
frame_cnt = 0
all_frames = []
while simulation_app.is_running():
    time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
    frame = env.visualize_motion(time)
    if args_cli.save_path:
        frame = frame.cpu().numpy().reshape(-1)
        all_frames.append(frame)
        # 如果保存模式,只播放一次
        if frame_cnt >= (env.motion_len - 1):
            break
    frame_cnt += 1
```

**关键改进**:
1. **循环播放**: 由于 `frame_cnt % (env.motion_len)` 的取模运算,动作会自动循环回到开始
2. **保存模式**: 如果指定了 `--save_path`,仍然只播放一次并保存数据
3. **可视化模式**: 没有 `--save_path` 时,动作会无限循环播放

#### 使用方法

修改后直接运行相同的命令即可循环播放:

```bash
# 循环播放 G1 跑步动作
python legged_lab/scripts/play_amp_animation.py --task=g1_run --num_envs=1

# 或使用 IsaacLab 脚本
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1
```

**操作说明**:
- 动作会自动循环播放,无需点击任何按钮
- 使用 `Ctrl+C` 或关闭窗口停止播放
- 添加 `--save_path` 参数仍然只保存一次数据

#### 相关文件位置
- **修改文件**: `legged_lab/scripts/play_amp_animation.py:77-86`

---

## 10. G1 机器人重定向动作不一致问题完整诊断

### 提问
现在运行python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1等发现g1机器人动作基本正确，但好像还是和重定向结果不一样，体现在机器人走路时摇晃而且手部摆动幅度不一致，这是因为什么，再检查一下各个关节以及数据的对齐情况和零点的对应情况

### 回答

#### 完整诊断分析

经过系统性排查,发现G1机器人走路摇晃和手臂不对称的问题有以下几个原因:

#### 1️⃣ 关节零点定义检查 ✅

**URDF vs MuJoCo XML 零点对比**:

| 关节 | URDF (IsaacLab) | MuJoCo XML (GMR) | 结论 |
|-----|----------------|------------------|-----|
| hip_roll | rpy='0 -0.1749 0' (-10.02°) | quat='0.996179 0 -0.0873386 0' (-10°) | ✅ 一致 |
| shoulder_pitch | rpy='0.27931 0 0' (16°) | quat='0.990264 0.139201 ...' (16°) | ✅ 一致 |
| shoulder_roll | rpy='-0.27925 0 0' (-16°) | quat='0.990268 -0.139172 0 0' (-16°) | ✅ 一致 |

**结论**: 零点定义一致,不是问题根源。

#### 2️⃣ 关节限位差异 ⚠️

**Left Shoulder Roll 限位对比**:
- URDF: `-1.5882 ~ 2.2515` rad (约 -91° ~ 129°)
- GMR:  `-0.6 ~ 2.2515` rad (约 -34° ~ 129°)

**影响**: URDF下限更宽松,如果GMR重定向时某些动作超出限制被截断,在IsaacLab回放时不会被截断,可能导致姿态差异。

#### 3️⃣ 关节顺序映射检查 ✅

**当前 g1_env.py 中的映射** (line 273-276):
```python
dof_pos[:, self.left_leg_ids]  = visual_motion_frame[6:12]   # GMR[0:6]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # GMR[6:12]
dof_pos[:, self.left_arm_ids]  = visual_motion_frame[21:25]  # GMR[15:19]
dof_pos[:, self.right_arm_ids] = visual_motion_frame[28:32]  # GMR[22:26]
```

**GMR 29DOF 结构**:
```
[0:6]   左腿: hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[6:12]  右腿: 同上
[12:15] 腰部: waist_yaw, waist_roll, waist_pitch (跳过)
[15:19] 左臂: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19:22] 左手腕: wrist_roll, wrist_pitch, wrist_yaw (跳过)
[22:26] 右臂: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26:29] 右手腕: wrist_roll, wrist_pitch, wrist_yaw (跳过)
```

**结论**: 映射正确,已正确跳过腰部和手腕关节。

#### 4️⃣ 核心问题:AMPLoaderDisplay 数据截断 ⚠️⚠️⚠️

**问题确认**:
- 代码位置: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py:27-36, 73`
- 截断代码 (line 73): `motion_data[:, :AMPLoaderDisplay.JOINT_VEL_END_IDX]` → `motion_data[:, :52]`

**硬编码的常量**:
```python
JOINT_POS_SIZE = 26  # line 27
JOINT_VEL_SIZE = 26  # line 29
JOINT_VEL_END_IDX = JOINT_POSE_END_IDX + JOINT_VEL_SIZE = 26 + 26 = 52  # line 36
```

**截断详情**:
- 完整数据: 70维 = `[root(6) + dof_pos(29) + root_vel(6) + dof_vel(29)]`
- 实际读取: 52维 = `[root(6) + dof_pos(29) + root_vel(6) + dof_vel(11)]`
- **丢失数据: [52:70] = dof_vel[11:29]** (后18个DOF的速度)
  - 包括: waist速度(3) + 大部分arm速度 + 所有wrist速度

**为什么是26?**
- 原因: AMPLoaderDisplay最初为TienKung设计 (20个可控关节)
- TienKung motion文件可能是不同格式,或者26包含了其他数据
- G1有29个DOF,超出了硬编码的26限制

**当前处理** (g1_env.py:282):
```python
dof_vel[:, :] = 0.0  # Set all velocities to zero
```

**后果**:
1. 机器人回放时没有速度信息,依赖仿真器动力学计算
2. 导致动作不流畅,出现抖动和摇晃
3. 手臂摆动因速度信息缺失而不自然

#### 5️⃣ 左右对称性分析

**第一帧数据分析**:
```
Left shoulder_roll:   0.3833  |  Right:  -0.1792  (和: 0.2041)
Left shoulder_yaw:   -0.9065  |  Right:   0.2634  (和: -0.6431)
```

- `shoulder_roll`: 符号相反 ✓ (符合镜像对称)
- `shoulder_yaw`: 不是完全镜像对称 (这是行走动作的自然状态,不是静态姿态)

**结论**: 左右手臂在不同摆动相位,所以不对称是正常的。

#### 6️⃣ 综合诊断结果

**导致摇晃和手臂不对称的主要原因**:

1. ⚠️⚠️⚠️ **速度数据不完整** (主要问题)
   - AMPLoaderDisplay只读取52维,丢失后18个DOF速度
   - 当前代码将所有速度设为0,导致动作不自然

2. ⚠️ **关节限位差异**
   - GMR和URDF的关节限位不完全一致
   - 可能导致某些极限姿态的截断差异

3. ✅ **关节映射和零点已正确**
   - 关节顺序映射正确
   - 零点定义一致

#### 7️⃣ 解决方案建议

**方案1: 修复速度数据读取** (推荐)
- 修改RSL-RL库中的AMPLoaderDisplay类,读取完整70维数据
- 或在g1_env.py中直接读取motion文件

**方案2: 验证关节顺序**
```python
# 在g1_env.py:__init__中添加调试输出
print('left_leg_ids:', self.left_leg_ids)
print('left_leg_names:', [self.robot.joint_names[i] for i in self.left_leg_ids])
```
对比是否真的是 `[pitch, roll, yaw, knee, ankle_pitch, ankle_roll]`

**方案3: 检查GMR重定向质量**
- 在MuJoCo中回放GMR输出的PKL文件
- 对比MuJoCo和IsaacLab的动作差异
- 如果MuJoCo中也有问题,需要调整GMR参数

#### 8️⃣ 数据文件分析

**motion file结构** (walk1_2_start54_end61.txt):
```
维度: 70
[0:3]    root_pos
[3:6]    root_rot (euler)
[6:35]   dof_pos (29 DOF)
[35:38]  root_lin_vel
[38:41]  root_ang_vel
[41:70]  dof_vel (29 DOF)
```

**GMR关节顺序** (from MuJoCo XML):
```
[0-5]   left_leg:  pitch, roll, yaw, knee, ankle_pitch, ankle_roll
[6-11]  right_leg: pitch, roll, yaw, knee, ankle_pitch, ankle_roll
[12-14] waist:     yaw, roll, pitch (不使用)
[15-18] left_arm:  shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19-21] left_wrist (不使用)
[22-25] right_arm: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26-28] right_wrist (不使用)
```

#### 相关文件位置

- **环境实现**: `legged_lab/envs/g1/g1_env.py:237-359` (visualize_motion)
- **关节定义**: `legged_lab/envs/g1/g1_env.py:158-207`
- **URDF文件**: `legged_lab/assets/g1_29dof/urdf/g1_29dof.urdf`
- **GMR XML**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`
- **Motion数据**: `legged_lab/envs/g1/datasets/motion_visualization/walk1_2_start54_end61.txt`
- **数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py`

#### 下一步行动建议

1. ✅ **首要任务**: 验证find_joints()返回的实际关节顺序
2. ⚠️ **次要任务**: 修复速度数据读取问题
3. 🔍 **可选任务**: 对比MuJoCo和IsaacLab中相同关节值的姿态差异

---

## 11. 创建AMPLoaderDisplay_G1类解决数据截断问题

### 提问
那仿照原有类自己写一个AMPLoaderDisplay_G1类使代码能正常读取不截断，在g1中调用自己的这一类，不影响tienkung

### 回答

#### 解决方案

创建了专门为G1设计的`AMPLoaderDisplay_G1`类,支持完整70维数据读取,不会像原始`AMPLoaderDisplay`那样截断为52维。

#### 1️⃣ 新建AMPLoaderDisplay_G1类

**文件**: `rsl_rl/rsl_rl/utils/motion_loader_for_display_g1.py`

**关键特性**:

```python
class AMPLoaderDisplay_G1:
    """Motion loader specifically designed for G1 robot with 29 DOF."""

    # G1 has 29 DOF (including waist and wrist joints)
    DOF_SIZE = 29

    # Complete data structure (70 dims)
    ROOT_POS_SIZE = 3       # [0:3]
    ROOT_ROT_SIZE = 3       # [3:6]
    DOF_POS (29 DOF)        # [6:35]
    ROOT_LIN_VEL_SIZE = 3   # [35:38]
    ROOT_ANG_VEL_SIZE = 3   # [38:41]
    DOF_VEL (29 DOF)        # [41:70]

    TOTAL_DATA_SIZE = 70    # ✅ 不截断!
```

**与原始AMPLoaderDisplay的对比**:

| 特性 | AMPLoaderDisplay (原始) | AMPLoaderDisplay_G1 (新) |
|-----|------------------------|-------------------------|
| 目标机器人 | TienKung (20 DOF) | G1 (29 DOF) |
| 数据维度 | 52 (硬编码) | 70 (完整数据) |
| DOF支持 | 26 (截断) | 29 (完整) |
| 速度数据 | 部分丢失 | ✅ 完整保留 |
| 是否截断 | ❌ 是 ([:52]) | ✅ 否 (完整读取) |

**核心方法**:

1. `get_full_frame_at_time(traj_idx, time)`: 返回完整70维帧数据
2. `get_dof_pos(frame)`: 提取DOF位置 [6:35]
3. `get_dof_vel(frame)`: 提取DOF速度 [41:70] ✅ 完整29个DOF
4. `get_root_lin_vel(frame)`: 提取根线速度 [35:38]
5. `get_root_ang_vel(frame)`: 提取根角速度 [38:41]

#### 2️⃣ 修改G1环境使用新类

**文件**: `legged_lab/envs/g1/g1_env.py`

**修改1: 导入新类** (line 39):
```python
# 原来:
from rsl_rl.utils import AMPLoaderDisplay

# 修改为:
from rsl_rl.utils.motion_loader_for_display_g1 import AMPLoaderDisplay_G1
```

**修改2: 使用新类初始化** (line 112-115):
```python
# Use G1-specific loader that supports full 70-dim data (no truncation)
self.amp_loader_display = AMPLoaderDisplay_G1(
    motion_files=self.cfg.amp_motion_files_display,
    device=self.device,
    time_between_frames=self.physics_dt
)
```

**修改3: 更新visualize_motion方法** (line 252-300):

```python
# 获取完整70维数据
visual_motion_frame = self.amp_loader_display.get_full_frame_at_time(0, time)

# DOF位置映射 [6:35]
dof_pos_offset = 6
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # 左腿
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # 右腿
dof_pos[:, self.left_arm_ids] = visual_motion_frame[21:25]   # 左臂 (跳过waist)
dof_pos[:, self.right_arm_ids] = visual_motion_frame[28:32]  # 右臂 (跳过左手腕)

# DOF速度映射 [41:70] - ✅ 现在完整了!
dof_vel_offset = 41
dof_vel[:, self.left_leg_ids] = visual_motion_frame[41:47]   # 左腿速度
dof_vel[:, self.right_leg_ids] = visual_motion_frame[47:53]  # 右腿速度
dof_vel[:, self.left_arm_ids] = visual_motion_frame[56:60]   # 左臂速度 (跳过waist)
dof_vel[:, self.right_arm_ids] = visual_motion_frame[63:67]  # 右臂速度 (跳过左手腕)

# Root速度 [35:38] lin_vel, [38:41] ang_vel - ✅ 也完整了!
lin_vel = visual_motion_frame[35:38].clone()
ang_vel = visual_motion_frame[38:41].clone()
```

#### 3️⃣ 对比:修改前后

**修改前 (使用AMPLoaderDisplay)**:
```python
# ❌ 只能读取52维
visual_motion_frame[0:52]

# ❌ 速度数据不完整
dof_vel[:, :] = 0.0  # 所有速度设为0

# ❌ root角速度设为0
ang_vel = torch.zeros_like(lin_vel)
```

**修改后 (使用AMPLoaderDisplay_G1)**:
```python
# ✅ 读取完整70维
visual_motion_frame[0:70]

# ✅ 完整的DOF速度数据
dof_vel[41:47], dof_vel[47:53], dof_vel[56:60], dof_vel[63:67]

# ✅ 完整的root角速度
ang_vel = visual_motion_frame[38:41].clone()
```

#### 4️⃣ 对TienKung的影响

**✅ 完全不影响TienKung**:
- TienKung环境仍使用原始`AMPLoaderDisplay`类
- 只有G1环境使用新的`AMPLoaderDisplay_G1`类
- 两个类完全独立,互不干扰

#### 5️⃣ 预期效果

修复后应该解决以下问题:

1. ✅ **消除摇晃**: 有了完整的速度信息,机器人动作会更流畅
2. ✅ **手臂自然摆动**: 手臂速度数据完整,摆动幅度应该一致
3. ✅ **角速度正确**: Root角速度不再为0,转身动作更自然
4. ✅ **动作保真**: 重定向后的动作应该与GMR MuJoCo中的一致

#### 6️⃣ 验证方法

运行可视化检查效果:

```bash
python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1
```

观察:
- 机器人走路是否还摇晃
- 左右手臂摆动是否对称自然
- 转身时的角速度是否正确
- 整体动作是否流畅连贯

#### 相关文件位置

**新增文件**:
- `rsl_rl/rsl_rl/utils/motion_loader_for_display_g1.py` (新建,300+行)

**修改文件**:
- `legged_lab/envs/g1/g1_env.py:39` (导入)
- `legged_lab/envs/g1/g1_env.py:112-115` (初始化)
- `legged_lab/envs/g1/g1_env.py:252-300` (visualize_motion方法)

**不受影响**:
- `legged_lab/envs/tienkung/tienkung_env.py` (仍使用AMPLoaderDisplay)
- `rsl_rl/rsl_rl/utils/motion_loader_for_display.py` (原始类保持不变)

---

## 12. G1 机器人完整关节映射(包括腰部和腕部)

### 提问
这里g1机器人的动作还是和重定向的不一致,检查一下机器人配置文件和~/project/GMR项目里的tiekunglab_g1_29dof的这个机器人有什么差别,机器人还是在踩到地面上时会摇晃而重定向文件并不会,而且这里的手的摆动也不对

### 回答

#### 详细诊断过程

经过系统性排查 TienKung-Lab 和 GMR 项目中的 G1 机器人配置,发现以下关键问题:

#### 1️⃣ 机器人配置文件对比 ✅

**Python 配置文件** (`g1_29dof.py`):
- TienKung-Lab: `legged_lab/assets/g1_29dof/g1_29dof.py`
- GMR: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/g1_29dof.py`
- **结论**: 两个文件完全相同 ✅

**URDF 文件**:
- TienKung-Lab: `legged_lab/assets/g1_29dof/urdf/g1_29dof.urdf`
- GMR: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/urdf/g1_29dof.urdf`
- **结论**: 两个文件完全相同 ✅

**USD 物理配置文件**:
- `g1_29dof_physics.usd` 文件也完全一致 ✅

#### 2️⃣ 发现的核心问题

**问题 1: Root 高度偏移过大** ⚠️⚠️

**位置**: `legged_lab/envs/g1/g1_env.py:290`

```python
# 原代码
root_pos[2] += 0.3  # 将机器人抬高 0.3 米
```

**影响**:
- 机器人被抬高 30cm,着地时产生较大冲击
- 导致着地瞬间的摇晃和振荡

**修复**:
```python
# 修改后
root_pos[2] += 0.05  # 改为 0.05 米,减少着地冲击
```

**问题 2: 缺少腰部关节映射** ⚠️⚠️⚠️

**位置**: `legged_lab/envs/g1/g1_env.py:268-285`

**GMR 数据包含的 29 DOF 结构**:
```
[0:6]   左腿 (6 DOF)
[6:12]  右腿 (6 DOF)
[12:15] 腰部 (3 DOF): waist_yaw, waist_roll, waist_pitch  ← 原代码未映射!
[15:19] 左臂 (4 DOF)
[19:22] 左手腕 (3 DOF)
[22:26] 右臂 (4 DOF)
[26:29] 右手腕 (3 DOF)
```

**原代码问题**:
- 注释声明 "G1 environment uses 20 DOF: [legs(12) + arms(8)], no waist and wrist joints"
- 但腰部关节对保持机器人稳定性和自然的手臂摆动**至关重要**
- GMR 重定向数据中包含腰部运动,不映射会导致腰部保持在 0 位置

**修复 1: 添加腰部关节索引查找** (line 199-206):
```python
self.waist_ids, _ = self.robot.find_joints(
    name_keys=[
        "waist_yaw_joint",
        "waist_roll_joint",
        "waist_pitch_joint",
    ],
    preserve_order=True,
)
```

**修复 2: 添加腰部 DOF 位置映射** (line 283):
```python
dof_pos[:, self.waist_ids] = visual_motion_frame[dof_pos_offset+12:dof_pos_offset+15]  # [18:21]
```

**修复 3: 添加腰部 DOF 速度映射** (line 291):
```python
dof_vel[:, self.waist_ids] = visual_motion_frame[dof_vel_offset+12:dof_vel_offset+15]  # [53:56]
```

**问题 3: 缺少手腕关节映射** (用户要求补充)

虽然原注释说不使用手腕关节,但用户要求补上以获得更完整的动作还原。

**修复 1: 添加手腕关节索引查找** (line 207-222):
```python
self.left_wrist_ids, _ = self.robot.find_joints(
    name_keys=[
        "left_wrist_roll_joint",
        "left_wrist_pitch_joint",
        "left_wrist_yaw_joint",
    ],
    preserve_order=True,
)
self.right_wrist_ids, _ = self.robot.find_joints(
    name_keys=[
        "right_wrist_roll_joint",
        "right_wrist_pitch_joint",
        "right_wrist_yaw_joint",
    ],
    preserve_order=True,
)
```

**修复 2: 添加手腕 DOF 位置映射** (line 301-303):
```python
dof_pos[:, self.left_wrist_ids] = visual_motion_frame[dof_pos_offset+19:dof_pos_offset+22]   # [25:28]
dof_pos[:, self.right_wrist_ids] = visual_motion_frame[dof_pos_offset+26:dof_pos_offset+29]  # [32:35]
```

**修复 3: 添加手腕 DOF 速度映射** (line 311-313):
```python
dof_vel[:, self.left_wrist_ids] = visual_motion_frame[dof_vel_offset+19:dof_vel_offset+22]   # [60:63]
dof_vel[:, self.right_wrist_ids] = visual_motion_frame[dof_vel_offset+26:dof_vel_offset+29]  # [67:70]
```

#### 3️⃣ 完整的数据映射结构

修复后的映射支持**完整 29 DOF**:

**DOF 位置 [6:35]**:
```python
[6:12]   左腿    → self.left_leg_ids
[12:18]  右腿    → self.right_leg_ids
[18:21]  腰部    → self.waist_ids       ✅ 新增
[21:25]  左臂    → self.left_arm_ids
[25:28]  左手腕  → self.left_wrist_ids  ✅ 新增
[28:32]  右臂    → self.right_arm_ids
[32:35]  右手腕  → self.right_wrist_ids ✅ 新增
```

**DOF 速度 [41:70]**:
```python
[41:47]  左腿速度    → self.left_leg_ids
[47:53]  右腿速度    → self.right_leg_ids
[53:56]  腰部速度    → self.waist_ids       ✅ 新增
[56:60]  左臂速度    → self.left_arm_ids
[60:63]  左手腕速度  → self.left_wrist_ids  ✅ 新增
[63:67]  右臂速度    → self.right_arm_ids
[67:70]  右手腕速度  → self.right_wrist_ids ✅ 新增
```

#### 4️⃣ 修改总结

**修改文件**: `legged_lab/envs/g1/g1_env.py`

**修改位置**:
1. **Line 199-222**: 添加 `self.waist_ids`, `self.left_wrist_ids`, `self.right_wrist_ids`
2. **Line 283**: 添加腰部 DOF 位置映射
3. **Line 291**: 添加腰部 DOF 速度映射
4. **Line 291**: 减小 root 高度偏移 (0.3 → 0.05)
5. **Line 301-303**: 添加手腕 DOF 位置映射
6. **Line 311-313**: 添加手腕 DOF 速度映射
7. **Line 276-277**: 更新注释说明现在使用完整 29 DOF

#### 5️⃣ 预期效果

修复后应该解决的问题:

1. ✅ **消除着地摇晃**:
   - Root 高度偏移减小,着地更平稳
   - 腰部关节参与运动,提供更好的平衡

2. ✅ **手臂摆动正确**:
   - 腰部旋转带动上半身运动
   - 手腕关节参与,手部动作更自然

3. ✅ **与重定向数据一致**:
   - 所有 29 个 DOF 全部映射
   - 完整还原 GMR 重定向的动作

#### 6️⃣ 验证方法

运行可视化检查效果:
```bash
python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1
```

观察:
- 机器人着地时是否还摇晃
- 左右手臂摆动是否对称自然
- 腰部是否有自然的扭转运动
- 手腕动作是否跟随手臂协调

#### 相关文件位置

**修改文件**:
- `legged_lab/envs/g1/g1_env.py:199-222, 283, 291, 301-303, 311-313`

**参考文件**:
- GMR 关节定义: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`
- G1 配置文件: `legged_lab/assets/g1_29dof/g1_29dof.py`
- 动作数据加载: `rsl_rl/rsl_rl/utils/motion_loader_for_display_g1.py`

---

## 问题 22: G1 训练脚本需要修改吗?

**提问时间**: 2025-10-16

### 问题
要用 `python legged_lab/scripts/train.py --task=g1_walk --headless --logger=tensorboard --num_envs=4096` 训练,这个训练脚本本来是为 TienKung 机器人设计的,我要改什么地方吗?(之前可视化的时候改了一些硬编码以及漏掉的 waist 和 wrist 才正常)

### 回答

**结论: ✅ 不需要修改,可以直接训练**

之前为可视化做的修改已经完成了所有必要的适配,训练脚本没有硬编码。

#### 1️⃣ 已完成的适配

**关节映射完全支持** (`g1_env.py:159-227`):
- ✅ `waist_ids`: 腰部 3 个关节 (yaw, roll, pitch)
- ✅ `left_wrist_ids` 和 `right_wrist_ids`: 左右腕部各 3 个关节
- ✅ G1 的 29 DOF 完整映射 (腿12 + 腰3 + 臂4 + 腕3 + 臂4 + 腕3)

**动作数据加载器适配**:
- ✅ 使用 `AMPLoaderDisplay_G1` 支持完整 70 维数据
- ✅ 格式: [root_pos(3) + root_rot(3) + dof_pos(29) + root_lin_vel(3) + root_ang_vel(3) + dof_vel(29)]

**训练脚本无硬编码** (`train.py`):
- ✅ 通过 `task_registry` 动态加载任务配置
- ✅ 无任何针对 TienKung 的硬编码
- ✅ 自动检测任务名包含 "sensor" 时启用相机

**配置文件已就绪** (`g1_walk_cfg.py`):
- ✅ 完整的环境配置 `G1WalkFlatEnvCfg`
- ✅ 完整的智能体配置 `G1WalkAgentCfg`
- ✅ AMP 动作文件路径已配置

#### 2️⃣ TienKung vs G1 主要差异

| 项目 | TienKung | G1 |
|------|----------|-----|
| **DOF 数量** | 20 (腿12 + 臂8) | 29 (腿12 + 腰3 + 臂8 + 腕6) |
| **关节命名** | `hip_roll_l_joint` | `left_hip_roll_joint` |
| **特殊关节** | 无腰部和腕部 | 有 waist 和 wrist |
| **数据加载器** | `AMPLoaderDisplay` (52维) | `AMPLoaderDisplay_G1` (70维) |

#### 3️⃣ 训练前建议检查

1. **数据集文件存在**:
   - 可视化数据: `legged_lab/envs/g1/datasets/motion_visualization/walk1_2_start58_end61.txt`
   - AMP 专家数据: `legged_lab/envs/g1/datasets/motion_amp_expert/walk1_2_start58_end61.txt`

2. **观察空间维度**: 确保 `actor_obs_history_length=10` 与数据集一致

3. **动作缩放**: `action_scale=0.25` 可能需要根据 G1 实际调整

#### 4️⃣ 训练流程

训练脚本会自动:
1. 通过 `task_registry` 加载 `G1Env` 和 `G1WalkFlatEnvCfg`
2. 使用 `AMPLoaderDisplay_G1` 加载 29 DOF 动作数据
3. 初始化所有 29 个关节(包括 waist 和 wrist)
4. 使用 AMP-PPO 算法训练

#### 相关文件位置

**核心文件**:
- 环境实现: `legged_lab/envs/g1/g1_env.py`
- 配置文件: `legged_lab/envs/g1/g1_walk_cfg.py`
- 训练脚本: `legged_lab/scripts/train.py`
- 数据加载: `rsl_rl/rsl_rl/utils/motion_loader_for_display_g1.py`

---

## 问题 10: 训练流程详解 - OnPolicyRunner 和 AmpOnPolicyRunner

**提问时间**: 2025-10-16

### 问题描述
详细解释强化学习训练的核心流程,包括:
1. `OnPolicyRunner` vs `AmpOnPolicyRunner` 的区别
2. 训练脚本如何选择使用哪个 Runner
3. `OnPolicyRunner.learn()` 方法的完整执行流程

---

### 回答

#### 1️⃣ OnPolicyRunner vs AmpOnPolicyRunner 核心区别

**OnPolicyRunner (标准 PPO Runner)**:
- 位置: `rsl_rl/rsl_rl/runners/on_policy_runner.py:41-549`
- 算法: 标准 PPO (Proximal Policy Optimization)
- 奖励来源: 仅使用环境的任务奖励
- 不需要专家数据或判别器

**AmpOnPolicyRunner (AMP-PPO Runner)**:
- 位置: `rsl_rl/rsl_rl/runners/amp_on_policy_runner.py:42-597`
- 算法: AMP-PPO (Adversarial Motion Priors)
- 奖励来源: 任务奖励 + 风格奖励(通过判别器生成)
- 需要加载专家动作数据集

**关键差异对比**:

| 特性 | OnPolicyRunner | AmpOnPolicyRunner |
|------|----------------|-------------------|
| **算法** | 标准 PPO | AMP-PPO |
| **奖励来源** | 仅任务奖励 | 任务奖励 + 风格奖励 |
| **专家数据** | 不需要 | 需要加载动作数据集 |
| **判别器** | 无 | 有(区分专家/策略动作) |
| **AMP 观测** | 不使用 | 使用 `get_amp_obs_for_expert_trans()` |
| **训练目标** | 最大化任务奖励 | 最大化任务奖励 + 模仿专家风格 |

**AmpOnPolicyRunner 的额外组件**:
```python
# 1. AMP 专家数据加载器
amp_data = AMPLoader(
    motion_files=["legged_lab/envs/g1/datasets/motion_amp_expert/walk1_2_start58_end61.txt"],
    num_preload_transitions=200000
)

# 2. 判别器网络(区分专家和策略动作)
discriminator = Discriminator(
    amp_data.observation_dim * 2,  # 输入: [当前状态, 下一状态]
    amp_reward_coef=0.3,
    amp_discr_hidden_dims=[1024, 512, 256]
)

# 3. 训练循环中计算 AMP 奖励
rewards = discriminator.predict_amp_reward(
    amp_obs, next_amp_obs, rewards, normalizer=amp_normalizer
)
```

---

#### 2️⃣ 训练脚本如何选择 Runner

**完整决策链路**:

```
命令行参数: --task=g1_walk
         ↓
任务注册表查询: task_registry.get_cfgs("g1_walk")
         ↓
返回配置对象: G1WalkAgentCfg
         ↓
读取字段: runner_class_name = "AmpOnPolicyRunner"
         ↓
动态解析: eval("AmpOnPolicyRunner") → 获取类对象
         ↓
实例化: AmpOnPolicyRunner(env, agent_cfg, log_dir, device)
         ↓
开始训练: runner.learn(num_learning_iterations=50000)
```

**关键配置字段** (`legged_lab/envs/g1/g1_walk_cfg.py:289-340`):
```python
@configclass
class G1WalkAgentCfg(RslRlOnPolicyRunnerCfg):
    algorithm = RslRlPpoAlgorithmCfg(
        class_name="AMPPPO",  # ← 指定使用 AMP-PPO 算法
    )
    
    runner_class_name = "AmpOnPolicyRunner"  # ← 指定 Runner 类型
    
    # AMP 特有参数
    amp_reward_coef = 0.3
    amp_motion_files = ["legged_lab/envs/g1/datasets/motion_amp_expert/walk1_2_start58_end61.txt"]
    amp_num_preload_transitions = 200000
    amp_task_reward_lerp = 0.7  # 任务奖励和风格奖励的插值系数
```

**训练脚本动态加载** (`legged_lab/scripts/train.py:95-96`):
```python
runner_class = eval(agent_cfg.runner_class_name)  # "AmpOnPolicyRunner" → 类对象
runner = runner_class(env, agent_cfg.to_dict(), log_dir=log_dir, device=agent_cfg.device)
```

---

#### 3️⃣ OnPolicyRunner.learn() 方法详解

这是整个强化学习训练的主循环,分为 5 个阶段:

**阶段 1: 初始化日志系统** (line 149-171)
```python
# 根据 --logger=tensorboard 创建日志写入器
if self.logger_type == "tensorboard":
    from torch.utils.tensorboard import SummaryWriter
    self.writer = SummaryWriter(log_dir=self.log_dir, flush_secs=10)
```

**阶段 2: 训练前准备** (line 173-208)
```python
# 1. 随机化初始 episode 长度(增强探索)
if init_at_random_ep_len:
    self.env.episode_length_buf = torch.randint_like(
        self.env.episode_length_buf, high=int(self.env.max_episode_length)
    )

# 2. 获取初始观测
obs, extras = self.env.get_observations()
privileged_obs = extras["observations"].get("critic", obs)  # Critic 的特权观测

# 3. 初始化统计缓冲区
rewbuffer = deque(maxlen=100)  # 最近 100 个 episode 的总奖励
lenbuffer = deque(maxlen=100)  # 最近 100 个 episode 的长度
cur_reward_sum = torch.zeros(self.env.num_envs)  # 当前 episode 累积奖励
```

**阶段 3: 主训练循环 - 数据收集 (Rollout)** (line 209-266)
```python
for it in range(50000):  # max_iterations
    # 内层循环: 收集经验
    with torch.inference_mode():  # 推理模式(不计算梯度)
        for _ in range(24):  # num_steps_per_env
            # 1. 采样动作
            actions = self.alg.act(obs, privileged_obs)
            
            # 2. 环境步进
            obs, rewards, dones, infos = self.env.step(actions)
            # 此时在 4096 个并行环境中同时执行
            
            # 3. 观测归一化
            obs = self.obs_normalizer(obs)
            
            # 4. 存储经验到 Rollout Buffer
            self.alg.process_env_step(rewards, dones, infos)
            
            # 5. 统计信息记录
            cur_reward_sum += rewards
            cur_episode_length += 1
            
            # 6. 处理完成的 episode
            new_ids = (dones > 0).nonzero(as_tuple=False)
            rewbuffer.extend(cur_reward_sum[new_ids].cpu().numpy().tolist())
            cur_reward_sum[new_ids] = 0  # 重置已完成环境的计数器
```

**每次迭代收集的样本数**: 24 × 4096 = 98,304 个转换 (transitions)

**阶段 4: 计算回报和策略更新** (line 267-279)
```python
# 1. 使用 GAE 计算优势函数
self.alg.compute_returns(privileged_obs)
# 计算公式: A_t = δ_t + (γλ)δ_{t+1} + (γλ)²δ_{t+2} + ...
# 其中 δ_t = r_t + γV(s_{t+1}) - V(s_t)

# 2. 更新策略网络
loss_dict = self.alg.update()
```

**`self.alg.update()` 内部逻辑**:
```python
# (a) 多 epoch 小批量训练
for epoch in range(5):  # num_learning_epochs
    for batch in mini_batches (4个):  # num_mini_batches
        
        # (b) 计算 PPO 损失
        ratio = π_new(a|s) / π_old(a|s)  # 新旧策略比率
        surr1 = ratio * advantage
        surr2 = clip(ratio, 1-0.2, 1+0.2) * advantage  # clip_param=0.2
        actor_loss = -min(surr1, surr2).mean()
        
        # Critic 损失
        value_pred = V(s)
        critic_loss = (value_pred - returns)².mean()
        
        # 熵损失(鼓励探索)
        entropy_loss = -π(a|s).entropy().mean()
        
        # 总损失
        total_loss = actor_loss + critic_loss + 0.005 * entropy_loss
        
        # (c) 反向传播
        optimizer.zero_grad()
        total_loss.backward()
        torch.nn.utils.clip_grad_norm_(parameters, max_grad_norm=1.0)
        optimizer.step()
        
        # (d) 自适应学习率调整(schedule="adaptive")
        if KL_divergence > desired_kl:
            learning_rate *= 0.5
        elif KL_divergence < desired_kl / 2:
            learning_rate *= 2.0
```

**每次迭代的梯度更新次数**: 5 epochs × 4 batches = 20 次

**阶段 5: 日志记录和模型保存** (line 280-302)
```python
# 1. 记录训练指标到 TensorBoard
self.log(locals())  # 记录奖励、损失、FPS 等

# 2. 定期保存模型(每 100 次迭代)
if it % self.save_interval == 0:
    self.save(os.path.join(self.log_dir, f"model_{it}.pt"))
    # 保存内容: policy, optimizer, normalizer, iteration

# 3. 第一次迭代时保存代码状态(Git diff)
if it == start_iter:
    git_file_paths = store_code_state(self.log_dir, self.git_status_repos)
```

---

#### 4️⃣ 完整训练流程图

```
┌─────────────────────────────────────────┐
│ 初始化阶段                              │
│ - 创建 TensorBoard 日志                 │
│ - 随机化初始 episode 长度               │
│ - 获取初始观测                          │
│ - 初始化统计缓冲区                      │
└─────────────┬───────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│ 外层循环: for it in range(50000)        │
└─────────────┬───────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│ 数据收集阶段 (Rollout)                  │
│ for _ in range(24):  # num_steps_per_env│
│   1. actions = policy(obs)              │
│   2. obs, rewards, dones = env.step()   │
│   3. buffer.store(obs, actions, rewards)│
│   4. 统计奖励和 episode 长度             │
│                                          │
│ 收集 98,304 个样本 (24 × 4096)          │
└─────────────┬───────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│ 计算回报和优势                          │
│ - 使用 GAE 计算优势函数                 │
│ - 使用 Critic 网络评估状态价值          │
└─────────────┬───────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│ 策略更新阶段                            │
│ for epoch in range(5):                  │
│   for batch in mini_batches (4个):      │
│     1. 计算 PPO 损失                    │
│     2. 反向传播                         │
│     3. 梯度裁剪                         │
│     4. 优化器更新                       │
│     5. 自适应调整学习率                 │
│                                          │
│ 共执行 20 次梯度更新 (5 × 4)            │
└─────────────┬───────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│ 日志记录和保存                          │
│ - 记录指标到 TensorBoard                │
│ - 每 100 次迭代保存模型                 │
│ - 清空 episode 信息缓冲区               │
└─────────────┬───────────────────────────┘
              │
              ▼ (回到外层循环)
             ...
```

---

#### 5️⃣ 关键数值计算(基于 g1_walk 配置)

| 参数 | 值 | 说明 |
|------|-----|------|
| `num_envs` | 4096 | 并行环境数 |
| `num_steps_per_env` | 24 | 每个环境每次迭代的步数 |
| `max_iterations` | 50000 | 总迭代次数 |
| `num_learning_epochs` | 5 | 每次迭代训练 epoch 数 |
| `num_mini_batches` | 4 | Mini-batch 数量 |
| `save_interval` | 100 | 模型保存间隔 |
| **每次迭代收集样本数** | 98,304 | 24 × 4096 |
| **总训练样本数** | 49亿+ | 98,304 × 50,000 |
| **每次迭代梯度更新次数** | 20 | 5 × 4 |
| **总梯度更新次数** | 100万 | 20 × 50,000 |

**时间估算**:
- 数据收集: 24 步 × 0.005s(physics_dt) × 4(decimation) = 0.48s
- 策略更新: ~1-2s (取决于 GPU)
- 每次迭代总时间: ~2-3s
- 总训练时间: 50000 × 2.5s ≈ 35 小时

---

#### 6️⃣ 核心概念解释

**On-Policy 算法特性**:
- 每次更新前必须用**当前策略**收集新数据
- 旧数据不能重用(因为策略已改变)
- 相比 Off-Policy 算法(如 SAC)样本效率较低,但更稳定

**Actor-Critic 架构**:
- **Actor**: 策略网络 π(a|s),输入有限观测(关节位置、速度、IMU 等)
- **Critic**: 价值网络 V(s),可以输入特权观测(地形高度、摩擦系数等)
- 训练时 Critic 帮助评估动作好坏,部署时只用 Actor

**PPO 的 Clip 机制**:
```python
ratio = π_new(a|s) / π_old(a|s)
clipped_ratio = clip(ratio, 1-0.2, 1+0.2)  # 限制在 [0.8, 1.2]
loss = -min(ratio * A, clipped_ratio * A)
```
- 防止策略更新过大导致训练崩溃
- 保持新旧策略的接近程度

**GAE (Generalized Advantage Estimation)**:
- 平衡偏差(bias)和方差(variance)
- λ=0.95 (你的配置)控制权衡
- 比 TD(0) 或 MC 更稳定

---

#### 相关文件位置

**核心文件**:
- 标准 Runner: `rsl_rl/rsl_rl/runners/on_policy_runner.py`
- AMP Runner: `rsl_rl/rsl_rl/runners/amp_on_policy_runner.py`
- 训练脚本: `legged_lab/scripts/train.py`
- 任务注册: `legged_lab/utils/task_registry.py`
- G1 配置: `legged_lab/envs/g1/g1_walk_cfg.py`
- PPO 算法: `rsl_rl/rsl_rl/algorithms/ppo.py`
- AMP-PPO 算法: `rsl_rl/rsl_rl/algorithms/amp_ppo.py`

---

## 问题 11: episode_length_buf 的作用详解

**提问时间**: 2025-10-16

### 问题描述
`self.env.episode_length_buf` 在代码中起什么作用?它如何影响训练流程?

---

### 回答

#### 1️⃣ 核心定义

`episode_length_buf` 是一个**张量**,用于追踪每个并行环境当前 episode 已执行的步数。

**初始化** (`legged_lab/envs/base/base_env.py:131`):
```python
self.episode_length_buf = torch.zeros(self.num_envs, device=self.device, dtype=torch.long)
# 示例: [0, 0, 0, 0, ...] (4096 个环境,初始全为 0)
```

---

#### 2️⃣ 完整生命周期

**阶段 1: 初始化** (line 131)
```python
episode_length_buf = torch.zeros(4096)  # 所有环境从 0 开始
```

**阶段 2: 每步递增** (`base_env.py:240`)
```python
def step(self, actions: torch.Tensor):
    # ... 执行动作、物理仿真 ...
    
    self.episode_length_buf += 1  # ← 每个环境的计数器 +1
    
    # ... 检查重置条件 ...
```

**示例:**
```python
# 初始
episode_length_buf = [0, 0, 0, 0]

# 第 1 步后
episode_length_buf = [1, 1, 1, 1]

# 第 100 步后
episode_length_buf = [100, 100, 100, 100]
```

**阶段 3: 超时判断** (`base_env.py:269-270`)
```python
def check_reset(self):
    # 检查不期望的接触(如膝盖着地)
    reset_buf = (接触力 > 阈值)
    
    # ===== 核心:超时判断 =====
    time_out_buf = self.episode_length_buf >= self.max_episode_length
    reset_buf |= time_out_buf  # 合并终止条件
    
    return reset_buf, time_out_buf
```

**max_episode_length 的计算** (`base_env.py:96-97`):
```python
self.max_episode_length_s = 20.0  # 配置: 最大时长 20 秒
self.max_episode_length = np.ceil(20.0 / 0.02) = 1000 步
# step_dt = physics_dt * decimation = 0.005s * 4 = 0.02s
```

**作用:**
- 判断环境是否达到最大 episode 长度(1000 步)
- **防止无限运行**,强制重置
- 即使机器人表现完美,超时也会触发重置

**示例:**
```python
max_episode_length = 1000

# 某个时刻
episode_length_buf = [950, 1000, 500, 1001]
time_out_buf = [False, True, False, True]  # 环境 1 和 3 超时

# 这些环境会被重置
```

**阶段 4: 重置时归零** (`base_env.py:219`)
```python
def reset(self, env_ids: torch.Tensor):
    # ... 重置机器人状态 ...
    
    self.episode_length_buf[env_ids] = 0  # ← 重置指定环境的计数器
    
    # ... 其他操作 ...
```

**示例:**
```python
# 重置前
episode_length_buf = [50, 1000, 200, 1001]
env_ids = [1, 3]  # 环境 1 和 3 需要重置

# 重置后
episode_length_buf = [50, 0, 200, 0]  # 环境 1 和 3 归零
```

---

#### 3️⃣ 训练初始化时的随机化

**位置**: `rsl_rl/rsl_rl/runners/on_policy_runner.py:177-180`

```python
def learn(self, num_learning_iterations: int, init_at_random_ep_len: bool = False):
    if init_at_random_ep_len:
        self.env.episode_length_buf = torch.randint_like(
            self.env.episode_length_buf, 
            high=int(self.env.max_episode_length)
        )
        # 例如: [234, 789, 12, 956, 345, ...]
```

**作用:**
- 训练开始时,将每个环境的计数器随机设置为 0 到 1000 之间的值
- **打破同步性**:防止所有环境同时重置
- **增强探索性**:让训练数据覆盖 episode 的不同阶段

**为什么需要随机化?**

❌ **不随机化的问题**:
```python
# 所有环境同时开始
episode_length_buf = [0, 0, 0, 0, ...]  # 4096 个 0

# 1000 步后所有环境同时超时重置
episode_length_buf = [1000, 1000, 1000, 1000, ...]

# 重置后又同时开始
episode_length_buf = [0, 0, 0, 0, ...]
```

**后果:**
- **数据冗余**:每次迭代收集的样本都来自相似的 episode 阶段
- **训练不稳定**:所有环境同时重置会造成梯度突变

✅ **随机化后**:
```python
# 训练开始时随机分布
episode_length_buf = [234, 789, 12, 456, ...]

# 之后环境会在不同时刻重置
episode_length_buf = [500, 0, 800, 1000, ...]  # 交错重置
```

**好处:**
- 数据覆盖 episode 的**所有阶段**(开始、中期、接近超时)
- 避免环境同步重置导致的训练波动

---

#### 4️⃣ 完整时间线示例

```python
# ===== 训练初始化 =====
episode_length_buf = torch.zeros(4096)  # 全 0

# 随机化(train.py 中 init_at_random_ep_len=True)
episode_length_buf = torch.randint(0, 1000, size=(4096,))
# 例如: [234, 789, 12, 956, 345, ...]

# ===== 训练循环 =====
for it in range(50000):  # 外层迭代
    for step in range(24):  # 内层数据收集
        actions = policy(obs)
        obs, rewards, dones, infos = env.step(actions)
        
        # env.step() 内部执行:
        # 1. episode_length_buf += 1  (所有环境 +1)
        # 2. 检查超时: time_out = (episode_length_buf >= 1000)
        # 3. 检查摔倒: collision = (不期望接触力 > 阈值)
        # 4. 合并: reset_buf = time_out | collision
        # 5. 重置: episode_length_buf[reset_buf] = 0

# ===== 某个时刻的快照 =====
episode_length_buf = [
    456,   # 环境 0: 已运行 456 步
    0,     # 环境 1: 刚重置(刚摔倒或超时)
    999,   # 环境 2: 快要超时了(下一步会重置)
    234,   # 环境 3: 已运行 234 步
    1000,  # 环境 4: 达到最大长度(这一步会重置)
    ...
]
```

---

#### 5️⃣ 与其他变量的关系

| 变量 | 作用 | 数值(g1_walk) | 关系 |
|------|------|---------------|------|
| `episode_length_buf` | 当前 episode 步数 | 0-1000 | 递增计数器 |
| `max_episode_length_s` | 最大时长(秒) | 20.0 | 配置参数 |
| `step_dt` | 控制频率(秒) | 0.02 | physics_dt × decimation |
| `max_episode_length` | 最大步数 | 1000 | `max_episode_length_s / step_dt` |
| `time_out_buf` | 超时标志 | Bool | `episode_length_buf >= 1000` |
| `reset_buf` | 重置标志 | Bool | `time_out_buf | collision` |

**计算公式:**
```python
physics_dt = 0.005s  (200 Hz 物理仿真)
decimation = 4       (每 4 步物理仿真执行 1 次控制)
step_dt = 0.005s × 4 = 0.02s  (50 Hz 控制频率)

max_episode_length = 20.0s / 0.02s = 1000 步
```

---

#### 6️⃣ 代码位置总结

| 操作 | 位置 | 代码 |
|------|------|------|
| **初始化** | `base_env.py:131` | `episode_length_buf = torch.zeros(num_envs)` |
| **递增** | `base_env.py:240` | `episode_length_buf += 1` |
| **超时检查** | `base_env.py:269` | `time_out = (episode_length_buf >= max_episode_length)` |
| **重置归零** | `base_env.py:219` | `episode_length_buf[env_ids] = 0` |
| **训练随机化** | `on_policy_runner.py:177-180` | `episode_length_buf = torch.randint(0, 1000, ...)` |

---

#### 7️⃣ 核心要点总结

1. **追踪步数**: 记录每个环境当前 episode 已执行的步数
2. **超时判断**: 达到 1000 步时强制重置环境(即使没摔倒)
3. **防止无限运行**: 确保每个 episode 不超过 20 秒
4. **训练稳定性**: 通过随机化避免所有环境同步重置
5. **并行管理**: 每个环境独立计数,互不干扰
6. **数据多样性**: 随机初始化让训练数据覆盖 episode 的各个阶段

**实际影响:**
- 机器人即使站得很稳,也会在 20 秒后被重置
- 避免策略过拟合到 episode 的特定阶段
- 提高训练数据的覆盖范围和多样性

---

## 问题 12: privileged_obs 的 get() 方法详解

**提问时间**: 2025-10-16

### 问题描述
`privileged_obs = extras["observations"].get(self.privileged_obs_type, obs)` 这行代码中 `get()` 是什么用法?得到的是什么?

---

### 回答

#### 1️⃣ Python dict.get() 方法的用法

这是 Python 字典的**安全访问**方法:

```python
dict.get(key, default_value)
```

**参数:**
- `key`: 要查找的键
- `default_value`: 如果键不存在,返回的默认值

**示例:**
```python
my_dict = {"critic": [1, 2, 3], "teacher": [4, 5, 6]}

# 方法 1: 直接访问(键不存在会报错)
value = my_dict["critic"]   # 返回 [1, 2, 3]
value = my_dict["student"]  # ❌ KeyError: 'student'

# 方法 2: 使用 get()(键不存在返回默认值)
value = my_dict.get("critic", None)    # 返回 [1, 2, 3]
value = my_dict.get("student", None)   # 返回 None (不报错)
value = my_dict.get("student", [7, 8, 9])  # 返回 [7, 8, 9]
```

**优势:**
- 避免 `KeyError` 异常
- 代码更健壮
- 可以提供回退方案

---

#### 2️⃣ 代码的具体含义

```python
privileged_obs = extras["observations"].get(self.privileged_obs_type, obs)
```

**分解:**
- `extras["observations"]`: 字典,包含不同类型的观测
- `self.privileged_obs_type`: 要查找的键(值为 `"critic"` 或 `None`)
- `obs`: 默认值(如果键不存在,返回普通观测)

**等价于:**
```python
if self.privileged_obs_type in extras["observations"]:
    privileged_obs = extras["observations"][self.privileged_obs_type]
else:
    privileged_obs = obs
```

**在 g1_walk 任务中:**
```python
# self.privileged_obs_type = "critic"
privileged_obs = extras["observations"].get("critic", obs)

# 如果 "critic" 键存在:
#   返回 extras["observations"]["critic"]  (Critic 的特权观测)
# 如果 "critic" 键不存在:
#   返回 obs  (回退到普通 Actor 观测)
```

---

#### 3️⃣ self.privileged_obs_type 的值和来源

**初始化** (`on_policy_runner.py:67-76`):
```python
# 在 OnPolicyRunner.__init__() 中
obs, extras = self.env.get_observations()

if self.training_type == "rl":
    if "critic" in extras["observations"]:
        self.privileged_obs_type = "critic"  # ← PPO/AMP-PPO 使用
    else:
        self.privileged_obs_type = None

if self.training_type == "distillation":
    if "teacher" in extras["observations"]:
        self.privileged_obs_type = "teacher"  # ← 知识蒸馏使用
    else:
        self.privileged_obs_type = None
```

**在你的 g1_walk 任务中:**
- `training_type = "rl"` (因为使用 AMPPPO 算法)
- `self.privileged_obs_type = "critic"`

**可能的值:**
| 训练类型 | 值 | 说明 |
|---------|-----|------|
| RL (PPO/AMP-PPO) | `"critic"` | Actor-Critic 架构 |
| Distillation | `"teacher"` | 知识蒸馏(Teacher-Student) |
| 简单环境 | `None` | 不使用特权观测 |

---

#### 4️⃣ extras["observations"] 的结构

**来自环境** (`base_env.py:251` 和 `319-320`):

```python
def get_observations(self):
    actor_obs, critic_obs = self.compute_observations()
    self.extras["observations"] = {"critic": critic_obs}  # ← 构建字典
    return actor_obs, self.extras

def step(self, actions):
    # ... 执行动作 ...
    actor_obs, critic_obs = self.compute_observations()
    self.extras["observations"] = {"critic": critic_obs}  # ← 每步更新
    return actor_obs, reward_buf, self.reset_buf, self.extras
```

**结构:**
```python
extras = {
    "observations": {
        "critic": critic_obs  # [4096, critic_obs_dim] 的张量
    },
    # 可能还有其他键...
}
```

---

#### 5️⃣ Actor 观测 vs Critic 观测的差异

**Actor 观测** (`base_env.py:146-156`):
```python
current_actor_obs = torch.cat([
    ang_vel * self.obs_scales.ang_vel,           # 角速度(IMU 测量)
    projected_gravity * self.obs_scales.projected_gravity,  # 投影重力(IMU)
    command * self.obs_scales.commands,          # 速度指令
    joint_pos * self.obs_scales.joint_pos,       # 关节位置(编码器)
    joint_vel * self.obs_scales.joint_vel,       # 关节速度(编码器)
    action * self.obs_scales.actions,            # 上一步动作
], dim=-1)
```

**特点:**
- 仅包含**实际部署时可用**的信息
- 所有数据都可以从传感器测量得到
- Actor 网络部署时使用这些观测

**Critic 观测** (`base_env.py:160-162`):
```python
current_critic_obs = torch.cat([
    current_actor_obs,                           # ← 包含所有 actor 观测
    root_lin_vel * self.obs_scales.lin_vel,     # ← 额外:基座线速度(仿真真实值)
    feet_contact                                 # ← 额外:足底接触状态(力传感器)
], dim=-1)
```

**特点:**
- 包含 Actor 观测的**所有内容**
- 额外包含**特权信息**(训练时可用,部署时不可用或难以准确获取)

**特权信息详解:**

| 信息 | 为什么是特权信息 | 训练时 | 部署时 |
|------|------------------|--------|--------|
| `root_lin_vel` | IMU 积分会漂移,需要复杂的状态估计 | 仿真直接提供真实值 | 需要估计器(误差大) |
| `feet_contact` | 需要力传感器或阈值判断 | 仿真直接提供准确值 | 需要传感器或估计 |

**为什么需要特权观测?**
- **训练时**: Critic 网络有更多信息,可以更准确地评估状态价值
- **部署时**: Actor 网络只用有限信息,确保能在真实机器人上运行
- **优势**: 提高训练效率,同时保证部署可行性

---

#### 6️⃣ 完整执行流程

```python
# ===== 步骤 1: 初始化时确定特权观测类型 =====
obs, extras = self.env.get_observations()
# extras = {
#     "observations": {
#         "critic": critic_obs  # [4096, 101]
#     }
# }

if "critic" in extras["observations"]:
    self.privileged_obs_type = "critic"  # ← 设置为 "critic"

# ===== 步骤 2: 训练循环中获取观测 =====
for it in range(50000):
    for step in range(24):
        # 从环境获取观测
        obs, extras = self.env.get_observations()
        # obs: [4096, 96] (Actor 观测)
        # extras["observations"]["critic"]: [4096, 101] (Critic 观测)
        
        # 使用 get() 安全访问
        privileged_obs = extras["observations"].get(self.privileged_obs_type, obs)
        # 等价于: privileged_obs = extras["observations"].get("critic", obs)
        # 返回: [4096, 101] 的 Critic 观测
        
        # 传递给算法
        actions = self.alg.act(obs, privileged_obs)
        # Actor 网络使用 obs (有限信息)
        # Critic 网络使用 privileged_obs (完整信息)
        
        # 执行动作
        obs, rewards, dones, infos = self.env.step(actions)
```

---

#### 7️⃣ 实际数据示例

假设 G1 机器人有 29 个关节:

**Actor 观测维度计算:**
```python
ang_vel:          3  # 角速度
projected_gravity: 3  # 投影重力
command:          3  # 速度指令
joint_pos:       29  # 关节位置
joint_vel:       29  # 关节速度
action:          29  # 上一步动作
----------------------------
总计:            96 维
```

**Critic 观测维度计算:**
```python
actor_obs:       96  # 所有 Actor 观测
root_lin_vel:     3  # ← 额外:基座线速度
feet_contact:     2  # ← 额外:左右脚接触(0/1)
----------------------------
总计:           101 维
```

**实际张量:**
```python
# Actor 观测
obs.shape = [4096, 96]  # 4096 个环境,每个 96 维

# Critic 观测
extras["observations"]["critic"].shape = [4096, 101]  # 4096 个环境,每个 101 维

# 执行 get()
privileged_obs = extras["observations"].get("critic", obs)
privileged_obs.shape = [4096, 101]  # 返回 Critic 观测
```

---

#### 8️⃣ 为什么使用 get() 而不是直接访问?

**代码健壮性对比:**

❌ **直接访问(不推荐)**:
```python
privileged_obs = extras["observations"][self.privileged_obs_type]
# 如果 self.privileged_obs_type = None → TypeError
# 如果键不存在 → KeyError
```

✅ **使用 get()(推荐)**:
```python
privileged_obs = extras["observations"].get(self.privileged_obs_type, obs)
# 如果键不存在,自动回退到普通观测
# 不会抛出异常
```

**适应不同环境:**
- 有些简单环境可能不提供 critic 观测
- 使用 `get()` 可以优雅地处理这种情况
- 代码通用性更强

---

#### 9️⃣ 核心要点总结

1. **`get()` 方法**: 安全地从字典获取值,避免 KeyError
2. **`privileged_obs_type`**: 在 g1_walk 中值为 `"critic"`
3. **返回结果**: Critic 的特权观测张量 `[4096, 101]`
4. **回退机制**: 如果不存在,返回普通观测 `obs`
5. **Actor-Critic 架构**:
   - Actor: 使用 `obs` (有限信息,可部署)
   - Critic: 使用 `privileged_obs` (完整信息,仅训练)
6. **特权信息**: 基座真实速度、足底接触状态(部署时难以准确获取)

**实际意义:**
- 训练时 Critic 有更多信息,评估更准确
- 部署时 Actor 只用传感器可测量的信息
- 平衡训练效率和部署可行性

---

#### 相关文件位置

**核心文件**:
- Runner 初始化: `rsl_rl/rsl_rl/runners/on_policy_runner.py:67-76`
- 环境观测计算: `legged_lab/envs/base/base_env.py:136-190`
- 观测返回: `legged_lab/envs/base/base_env.py:317-320`
- 训练循环使用: `rsl_rl/rsl_rl/runners/on_policy_runner.py:183-185`

---

## 73. 为 G1 机器人创建专用的 AMPLoader 类以支持训练

### 提问
我训练g1时检查发现AMPLoader等关节数都是根据tienkung机器人硬编码的(20 DOF),都需要重新创建一个类给g1用(29 DOF),根据g1创建类并修改相关训练代码,使`python legged_lab/scripts/train.py --task=g1_walk --headless --logger=tensorboard --num_envs=4096`能正常用于g1的训练。

### 回答

#### 问题分析
TienKung 机器人有 20 个自由度(DOF),而 G1 机器人有 29 个自由度(包括 waist 和 wrist 关节)。原有的 AMPLoader 类硬编码了 20 DOF,导致无法用于 G1 训练。

#### G1 vs TienKung DOF 对比
- **TienKung**: 20 DOF = 腿部(12) + 手臂(8)
- **G1**: 29 DOF = 腿部(12) + 腰部(3) + 手臂(8) + 手腕(6)

#### AMP 数据格式
- **TienKung**: 52 dims = dof_pos(20) + dof_vel(20) + end_effector(12)
- **G1**: 70 dims = dof_pos(29) + dof_vel(29) + end_effector(12)

#### 解决方案

##### 1. 创建 G1 专用的 AMPLoader 类
**文件**: `rsl_rl/rsl_rl/utils/motion_loader_g1.py`

创建了 `AMPLoader_G1` 类,支持 29 DOF 的 G1 机器人:
- `JOINT_POS_SIZE = 29`
- `JOINT_VEL_SIZE = 29`
- `END_EFFECTOR_POS_SIZE = 12`
- 总维度: 70 dims

**关键特性**:
- 完整支持 G1 的 29 个关节
- 数据格式: [dof_pos(29) + dof_vel(29) + end_effector_pos(12)]
- DOF 顺序: left_leg(6) + right_leg(6) + waist(3) + left_arm(4) + left_wrist(3) + right_arm(4) + right_wrist(3)

##### 2. 修改 AMP 训练 Runner 自动检测机器人类型
**文件**: `rsl_rl/rsl_rl/runners/amp_on_policy_runner.py`

添加了自动检测逻辑:
```python
# 根据动作空间维度自动检测机器人类型
num_actions = self.env.num_actions
if num_actions == 29:
    robot_type = "g1"
    amp_data = AMPLoader_G1(...)
elif num_actions == 20:
    robot_type = "tienkung"
    amp_data = AMPLoader(...)
```

##### 3. 更新导出模块
**文件**: `rsl_rl/rsl_rl/utils/__init__.py`

添加了 G1 专用加载器的导出:
```python
from .motion_loader_g1 import AMPLoader_G1
from .motion_loader_for_display_g1 import AMPLoaderDisplay_G1
```

##### 4. 修正 G1 配置文件
**文件**: 
- `legged_lab/envs/g1/g1_walk_cfg.py`
- `legged_lab/envs/g1/g1_run_cfg.py`

修改了 `min_normalized_std` 参数:
```python
min_normalized_std = [0.05] * 29  # G1 has 29 DOF (原来是 * 20)
```

##### 5. 修正 G1 环境的 AMP 观察输出
**文件**: `legged_lab/envs/g1/g1_env.py`

修改了两个关键函数以输出完整的 70 维数据:

**a) `get_amp_obs_for_expert_trans()`** (训练时使用):
```python
def get_amp_obs_for_expert_trans(self):
    # 返回 70 维: dof_pos(29) + dof_vel(29) + end_effector(12)
    return torch.cat((
        # DOF positions (29)
        left_leg_dof_pos, right_leg_dof_pos, waist_dof_pos,
        left_arm_dof_pos, left_wrist_dof_pos,
        right_arm_dof_pos, right_wrist_dof_pos,
        # DOF velocities (29)
        left_leg_dof_vel, right_leg_dof_vel, waist_dof_vel,
        left_arm_dof_vel, left_wrist_dof_vel,
        right_arm_dof_vel, right_wrist_dof_vel,
        # End effectors (12)
        left_hand_pos, right_hand_pos,
        left_foot_pos, right_foot_pos
    ), dim=-1)
```

**b) `visualize_motion()`** (生成专家数据时使用):
- 之前返回 52 维 (不包含 waist 和 wrist)
- 现在返回 70 维 (包含完整的 29 DOF)
- 与 `get_amp_obs_for_expert_trans()` 格式完全一致

##### 6. 生成新的 AMP 专家数据
需要重新运行 `play_amp_animation.py` 生成正确格式的 70 维专家数据:

```bash
python legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1 \
    --save_path=legged_lab/envs/g1/datasets/motion_amp_expert/walk1_2_start58_end61.txt \
    --fps 30.0
```

#### 修改文件清单
1. ✅ `rsl_rl/rsl_rl/utils/motion_loader_g1.py` - 新建 G1 专用 AMPLoader
2. ✅ `rsl_rl/rsl_rl/utils/__init__.py` - 导出新类
3. ✅ `rsl_rl/rsl_rl/runners/amp_on_policy_runner.py` - 自动检测机器人类型
4. ✅ `legged_lab/envs/g1/g1_env.py` - 修正输出为 70 维
5. ✅ `legged_lab/envs/g1/g1_walk_cfg.py` - 修正 min_normalized_std
6. ✅ `legged_lab/envs/g1/g1_run_cfg.py` - 修正 min_normalized_std

#### 训练命令
现在可以正常训练 G1:
```bash
python legged_lab/scripts/train.py \
    --task=g1_walk \
    --headless \
    --logger=tensorboard \
    --num_envs=4096
```

系统会自动:
1. 检测到 29 DOF 的 G1 机器人
2. 使用 `AMPLoader_G1` 加载 70 维专家数据
3. 正确处理所有 29 个关节的 AMP 奖励

#### 关键代码位置
- G1 AMPLoader 类: `rsl_rl/rsl_rl/utils/motion_loader_g1.py`
- 自动检测逻辑: `rsl_rl/rsl_rl/runners/amp_on_policy_runner.py:109-145`
- G1 环境 AMP 输出: `legged_lab/envs/g1/g1_env.py:613-687`
- G1 配置文件: `legged_lab/envs/g1/g1_walk_cfg.py`, `legged_lab/envs/g1/g1_run_cfg.py`

