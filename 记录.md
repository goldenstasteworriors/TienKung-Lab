# 交互记录

## 1. 创建 CLAUDE.md 文件

### 提问
请分析这个代码库并创建一个 CLAUDE.md 文件,用于指导未来的 Claude Code 实例在此仓库中工作。

### 回答
已成功分析 TienKung-Lab 代码库并创建了 `/home/ykj/project/TienKung-Lab/CLAUDE.md` 文件。

该文件包含以下内容:

1. **项目概述**
   - TienKung-Lab 是基于 IsaacLab 的全尺寸人形机器人强化学习运动控制框架
   - 技术栈: IsaacSim 4.5.0, IsaacLab 2.1.0, RSL_RL 2.3.1, Python 3.10, MuJoCo 3.3.2

2. **常用命令**
   - 安装与设置命令
   - 训练命令 (walk/run 任务)
   - 测试与可视化命令 (带/不带传感器)
   - Sim2Sim 验证命令
   - TensorBoard 和代码格式化命令

3. **架构设计**
   - 核心组件层次结构:
     - 任务注册系统 (`task_registry.py`)
     - 基础环境架构 (`BaseEnv`, `BaseEnvCfg`)
     - TienKung 环境实现 (walk/run 配置)
     - 奖励与感知系统 (MDP 奖励、相机、激光雷达)
     - RSL-RL 算法 (PPO, AMP-PPO)

   - 动作重定向工作流:
     - 数据集结构 (`motion_visualization/`, `motion_amp_expert/`)
     - 数据转换流程 (GMR → 可视化数据 → 专家数据)

   - 关键配置参数:
     - 步态参数 (周期、离地比例、相位偏移)
     - 奖励权重
     - 仿真参数 (physics_dt: 0.005s, control freq: 50Hz)

   - 导出与部署:
     - 自动导出 JIT 和 ONNX 格式
     - 包含观察归一化器

   - 与 IsaacLab 的集成方式

4. **开发注意事项**
   - 带传感器任务的自动相机渲染
   - 策略自动导出机制
   - 日志路径结构
   - Conda 环境使用建议

文件位置: `/home/ykj/project/TienKung-Lab/CLAUDE.md`

## 2. G1 重定向效果不佳的问题排查与解决

### 提问
现在用的 g1 重定向显示出来的效果不好,现在在排查原因,我觉得可能是因为在 gmr 中我用的是 g1_mocap_29dof.xml 而在这里我用的是 g1_29dof.xml 的原因,但是 gmr 中没有 mocap 版本 xml 的 urdf 文件,这个项目在哪里要用到 urdf 文件,能不能改为使用 mocap 版本的 xml 进行 Motion Visualization 这一步,调试到可以正常执行并显示可视化界面让我检查重定向结果,用 dance1_2.txt 来可视化。

### 回答

#### 问题分析
1. **IsaacLab 使用的是 USD 文件,不是 XML**
   - 在 `legged_lab/assets/g1_29dof/g1_29dof.py:36` 中,项目使用 `g1_29dof.usd` 文件
   - XML 文件 (`g1_29dof.xml` 和 `g1_mocap_29dof.xml`) 是为 MuJoCo/GMR 准备的,不在 IsaacLab 中使用

2. **g1_29dof.xml 和 g1_mocap_29dof.xml 的主要差异**
   - **关节范围限制不同**: mocap 版本的关节范围更受限(如 hip_pitch 从 [-2.5307, 2.8798] 改为 [-1.57, 1.57])
   - **模型命名**: `g1_29dof` vs `g1_mocap`
   - **网格文件名**: 某些 link 使用了 `_rev_1_0` 后缀的网格文件
   - **额外的 body**: mocap 版本添加了 `left_toe_link` 和 `pelvis_contour_link`
   - **关节类型**: `floating_base_joint` (type="free") vs `pelvis` (freejoint)

3. **dance1_2.txt 文件位置**
   - 原始位置: `legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt`
   - 需要复制到: `legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt`

#### 解决方案

**步骤 1: 复制 dance1_2.txt 到 G1 数据集目录**
```bash
mkdir -p legged_lab/envs/g1/datasets/motion_visualization
cp legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt \
   legged_lab/envs/g1/datasets/motion_visualization/
```

**步骤 2: 修改 G1 环境配置**
已修改以下文件使用 dance1_2.txt:
- `legged_lab/envs/g1/g1_walk_cfg.py:164`
- `legged_lab/envs/g1/g1_run_cfg.py:164`

修改内容:
```python
amp_motion_files_display = ["legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt"]
```

**步骤 3: 验证配置**
运行测试脚本 `test_g1_dance_config.py` 确认:
- ✅ dance1_2.txt 文件存在
- ✅ JSON 格式正确
- ✅ 包含 3944 帧数据
- ✅ 每帧 70 维数据
- ✅ 两个配置文件都已更新

**步骤 4: 运行可视化**
使用以下命令运行 G1 动作可视化:
```bash
# 方式 1: 使用 IsaacLab 脚本 (推荐)
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1

# 方式 2: 直接使用 Python (需要设置环境变量)
LD_LIBRARY_PATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni:$LD_LIBRARY_PATH \
PYTHONPATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni/kernel/py:$PYTHONPATH \
conda run -n TieKung python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1

# 方式 3: 使用 g1_run 任务
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_run --num_envs=1
```

#### 重要发现

1. **XML vs USD 的区别**
   - IsaacSim/IsaacLab 使用 USD (Universal Scene Description) 格式
   - GMR 使用 MuJoCo XML 格式
   - 两者的差异不会影响 IsaacLab 的可视化,因为 IsaacLab 不读取 XML 文件

2. **动作数据格式**
   - `gmr_data_conversion.py` 将 GMR 输出的 PKL 文件转换为项目所需的 TXT 格式
   - 格式包含: `[root_pos(3), euler_angles(3), dof_pos(26), root_lin_vel(3), root_ang_vel(3), dof_vel(26)]`
   - G1 29DOF: 26 个可控关节 (6 腿部 × 2 + 3 腰部 + 4 手臂 × 2 + 3 手腕 × 2)

3. **可视化流程**
   - `play_amp_animation.py` 使用 `AMPLoaderDisplay` 加载 TXT 文件
   - `G1Env.visualize_motion()` 方法根据时间戳设置机器人状态
   - 数据映射: 从 TXT 格式的 dof_pos/vel 映射到 G1 的特定关节顺序

#### 下一步建议

1. **检查重定向质量**
   - 在 IsaacSim 可视化界面中观察 dance1_2 动作
   - 检查关节角度是否在合理范围内
   - 观察是否有不自然的姿态或抖动

2. **如果效果仍不理想**
   - 可能需要调整 GMR 的重定向参数
   - 检查 G1 的关节限制是否与 mocap 版本一致
   - 考虑在 `g1_29dof.py` 中调整关节范围限制

3. **生成 AMP 训练数据**
   ```bash
   /home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
       --task=g1_walk --num_envs=1 \
       --save_path legged_lab/envs/g1/datasets/motion_amp_expert/dance1_2.txt
   ```

#### 相关文件位置
- G1 USD 配置: `legged_lab/assets/g1_29dof/g1_29dof.py:36`
- G1 环境类: `legged_lab/envs/g1/g1_env.py`
- 可视化脚本: `legged_lab/scripts/play_amp_animation.py`
- 数据转换脚本: `legged_lab/scripts/gmr_data_conversion.py`
- Walk 配置: `legged_lab/envs/g1/g1_walk_cfg.py:164`
- Run 配置: `legged_lab/envs/g1/g1_run_cfg.py:164`

---

## 3. visualize_motion 实现原理

### 提问
visualize_motion这一步是怎么实现的,怎么读取的数据然后用的哪里的机器人配置文件进行可视化

### 回答

#### 整体工作流程

`visualize_motion` 是一个用于在 IsaacSim 中播放动作捕捉数据的可视化系统,主要分为以下几个步骤:

**1. 数据加载阶段 (初始化时)**

在环境初始化时 (`legged_lab/envs/tienkung/tienkung_env.py:123-126`):
```python
self.amp_loader_display = AMPLoaderDisplay(
    motion_files=self.cfg.amp_motion_files_display,
    device=self.device,
    time_between_frames=self.physics_dt
)
self.motion_len = self.amp_loader_display.trajectory_num_frames[0]
```

**2. 数据文件配置**

动作数据文件在各个任务配置中定义,例如在 `legged_lab/envs/tienkung/walk_cfg.py:164`:
```python
amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
```

**3. 数据读取与解析** (`rsl_rl/rsl_rl/utils/motion_loader_for_display.py`)

`AMPLoaderDisplay` 类负责读取和解析动作数据:
- **文件格式**: JSON 格式的 TXT 文件,包含:
  - `LoopMode`: 循环模式 ("Wrap")
  - `FrameDuration`: 帧间隔时间 (通常 1/30 秒)
  - `EnableCycleOffsetPosition/Rotation`: 循环偏移设置
  - `MotionWeight`: 动作权重
  - `Frames`: 动作帧数组

- **数据结构** (motion_loader_for_display.py:68-79):
  ```python
  motion_data = np.array(motion_json["Frames"])
  # 提取关节位置和速度数据 (前52维)
  self.trajectories_full.append(
      torch.tensor(motion_data[:, :AMPLoaderDisplay.JOINT_VEL_END_IDX], ...)
  )
  ```

- **数据维度**:
  - `JOINT_POS_SIZE = 26`: 关节位置维度
  - `JOINT_VEL_SIZE = 26`: 关节速度维度
  - 总共 52 维 (26 位置 + 26 速度)

**4. 可视化执行** (`legged_lab/scripts/play_amp_animation.py:54-87`)

主循环调用 `visualize_motion`:
```python
while simulation_app.is_running():
    while True:
        time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
        frame = env.visualize_motion(time)  # 核心调用
        frame_cnt += 1
        if frame_cnt >= (env.motion_len - 1):
            break
    break
```

**5. visualize_motion 方法详解** (`legged_lab/envs/tienkung/tienkung_env.py:248-352`)

核心实现步骤:

**(1) 获取指定时间的动作帧** (248-262行):
```python
visual_motion_frame = self.amp_loader_display.get_full_frame_at_time(0, time)
```
- `get_full_frame_at_time` 方法通过线性插值获取精确时刻的动作数据
- 数据格式: `[root_pos(3), euler(3), dof_pos(26), root_lin_vel(3), ang_vel(3), dof_vel(26)]`

**(2) 映射关节数据到机器人** (265-276行):
```python
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # 左腿 6DOF
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # 右腿 6DOF
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]   # 左臂 4DOF
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26]  # 右臂 4DOF
# 速度同理映射
```

**(3) 写入机器人状态** (278-302行):
```python
# 写入关节位置和速度
self.robot.write_joint_position_to_sim(dof_pos)
self.robot.write_joint_velocity_to_sim(dof_vel)

# 处理 Root 状态 (位置、姿态、速度)
root_pos = visual_motion_frame[:3].clone()
root_pos[2] += 0.3  # Z轴偏移

# Euler 角转四元数
euler = visual_motion_frame[3:6].cpu().numpy()
quat_xyzw = Rotation.from_euler("XYZ", euler, degrees=False).as_quat()
quat_wxyz = torch.tensor([quat_xyzw[3], quat_xyzw[0], quat_xyzw[1], quat_xyzw[2]], ...)

# 构建完整 root_state: [x,y,z, qw,qx,qy,qz, vx,vy,vz, wx,wy,wz]
self.robot.write_root_state_to_sim(root_state, env_ids)
```

**(4) 仿真更新** (303-305行):
```python
self.sim.render()
self.sim.step()
self.scene.update(dt=self.step_dt)
```

**(5) 计算末端执行器位置** (307-326行):
```python
# 计算左右手位置 (相对 root 的局部坐标)
left_hand_pos = self.robot.data.body_state_w[:, self.elbow_body_ids[0], :3] - ...
# 转换到 root 局部坐标系
left_hand_pos = quat_apply(quat_conjugate(self.robot.data.root_state_w[:, 3:7]), left_hand_pos)
# 同理计算脚部位置
```

**(6) 返回完整状态** (336-352行):
```python
return torch.cat((
    self.right_arm_dof_pos,   # 右臂关节位置
    self.left_arm_dof_pos,    # 左臂关节位置
    self.right_leg_dof_pos,   # 右腿关节位置
    self.left_leg_dof_pos,    # 左腿关节位置
    self.right_arm_dof_vel,   # 速度同理...
    self.left_arm_dof_vel,
    self.right_leg_dof_vel,
    self.left_leg_dof_vel,
    left_hand_pos,            # 左手位置
    right_hand_pos,           # 右手位置
    left_foot_pos,            # 左脚位置
    right_foot_pos            # 右脚位置
), dim=-1)
```

#### 机器人配置文件

**1. 主要配置文件路径**:

- **USD 模型文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
  - 在 `legged_lab/assets/tienkung2_lite/tienkung.py:36` 中引用

- **关节配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
  ```python
  TIENKUNG2LITE_CFG = ArticulationCfg(
      spawn=sim_utils.UsdFileCfg(
          usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
          ...
      ),
      init_state=ArticulationCfg.InitialStateCfg(
          pos=(0.0, 0.0, 1.0),
          joint_pos={...},  # 初始关节位置
          joint_vel={".*": 0.0},
      ),
      actuators={
          "legs": ImplicitActuatorCfg(...),   # 腿部执行器配置
          "feet": ImplicitActuatorCfg(...),   # 脚部执行器配置
          "arms": ImplicitActuatorCfg(...),   # 手臂执行器配置
      },
  )
  ```

- **环境配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
  ```python
  class TienKungWalkFlatEnvCfg:
      amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
      scene: BaseSceneCfg = BaseSceneCfg(
          robot=TIENKUNG2LITE_CFG,  # 使用上述机器人配置
          terrain_type="generator",
          ...
      )
  ```

**2. 关节 ID 映射** (`legged_lab/envs/tienkung/tienkung_env.py:163-212`):

系统在初始化时通过 `find_joints` 方法获取关节索引:
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=["hip_roll_l_joint", "hip_pitch_l_joint", "hip_yaw_l_joint",
               "knee_pitch_l_joint", "ankle_pitch_l_joint", "ankle_roll_l_joint"],
    preserve_order=True,
)
# 同理获取 right_leg_ids, left_arm_ids, right_arm_ids, ankle_joint_ids 等
```

**3. Body ID 映射** (163-168行):
```python
self.feet_body_ids, _ = self.robot.find_bodies(
    name_keys=["ankle_roll_l_link", "ankle_roll_r_link"],
    preserve_order=True
)
self.elbow_body_ids, _ = self.robot.find_bodies(
    name_keys=["elbow_pitch_l_link", "elbow_pitch_r_link"],
    preserve_order=True
)
```

#### 数据流总结

```
1. TXT文件 (JSON格式)
   ↓ (AMPLoaderDisplay 读取)
2. Torch Tensor [N_frames, 52]
   ↓ (get_full_frame_at_time 插值)
3. 单帧数据 [root(6) + dof_pos(26) + root_vel(6) + dof_vel(26)]
   ↓ (visualize_motion 映射)
4. 机器人状态
   - dof_pos/vel → 按 joint_ids 映射到具体关节
   - root state → 写入机器人根部状态
   ↓ (IsaacSim 仿真)
5. 可视化显示 + 末端执行器位置计算
```

#### 关键文件位置汇总

- **可视化脚本**: `legged_lab/scripts/play_amp_animation.py:54-118`
- **环境实现**: `legged_lab/envs/tienkung/tienkung_env.py:248-352`
- **数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py:26-283`
- **机器人配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
- **任务配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
- **USD 模型**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`

#### 注意事项

1. **坐标系转换**:
   - Root 姿态使用欧拉角 (XYZ) 转四元数 (WXYZ)
   - 末端位置从世界坐标转换到 Root 局部坐标

2. **数据格式要求**:
   - 必须是 JSON 格式 TXT 文件
   - 包含 `FrameDuration`, `Frames` 等关键字段
   - 每帧数据至少 52 维 (26 pos + 26 vel)

3. **机器人配置一致性**:
   - USD 文件定义物理模型和视觉外观
   - ArticulationCfg 定义执行器参数
   - 关节顺序必须与数据文件匹配

---

## 4. USD 文件详解

### 提问
usd文件是什么

### 回答

#### 📚 基本概念

**USD** (Universal Scene Description,通用场景描述) 是由 **Pixar** 开发的一种开源框架和文件格式,用于描述、组合和模拟复杂的 3D 场景。

**核心特点**:
1. **通用性**: 描述完整的 3D 场景(几何、材质、灯光、相机、动画等)
2. **可组合性**: 支持场景分层和引用,可将多个 USD 文件组合
3. **高性能**: 针对大规模场景优化,支持延迟加载
4. **可扩展**: 支持自定义数据类型和属性
5. **行业标准**: 广泛应用于电影、游戏、机器人仿真等领域

#### 📁 USD 文件格式类型

| 扩展名 | 格式 | 特点 | 用途 |
|--------|------|------|------|
| `.usd` | 通用格式 | 可以是文本或二进制 | 一般用途 |
| `.usda` | ASCII 文本 | 人类可读,易于版本控制 | 调试、手动编辑 |
| `.usdc` | 二进制 Crate | 紧凑高效,加载快 | 生产环境 |
| `.usdz` | 压缩包 | 包含所有依赖资源 | 分发、AR 应用 |

在本项目中,使用的是 **`.usd` 格式**(实际为二进制 USD crate 0.8.0 版本):
```bash
$ file tienkung2_lite.usd
tienkung2_lite.usd: USD crate, version 0.8.0
```

#### 🤖 在机器人仿真中的应用

USD 文件在 IsaacSim/IsaacLab 中定义完整的机器人模型:

**1. 几何结构**:
- Links/Bodies: 机器人的刚体部件
- 网格文件引用: STL、OBJ 等格式的 3D 模型
- 视觉外观: 材质、纹理、颜色

**2. 物理属性**:
- 质量 (Mass)
- 惯性矩阵 (Inertia)
- 碰撞体 (Colliders): 凸包、网格、基本形状
- 摩擦系数、恢复系数

**3. 关节定义**:
- 关节类型: Revolute(旋转)、Prismatic(平移)、Fixed(固定)
- 关节轴向
- 关节限制 (位置、速度、力矩)
- 驱动参数 (刚度、阻尼)

**4. 传感器与附件**:
- 相机 (RGB、深度、分割)
- 激光雷达
- IMU、接触传感器等

#### 🔄 与其他格式的对比

| 格式 | 开发者 | 主要用途 | 优点 | 缺点 |
|------|--------|---------|------|------|
| **URDF** | ROS 社区 | ROS 机器人 | 简单易用,ROS 生态 | 功能有限,不支持复杂场景 |
| **MJCF/XML** | DeepMind | MuJoCo 仿真 | 物理仿真精确 | 专用格式,不通用 |
| **USD** | Pixar | 通用场景描述 | 功能强大,行业标准 | 学习曲线较陡 |
| **SDF** | OSRF | Gazebo 仿真 | 类似 URDF,功能更强 | 主要限于 Gazebo |

#### 📂 在 TienKung-Lab 项目中的使用

**项目中的 USD 文件结构**:
```
legged_lab/assets/tienkung2_lite/
├── usd/
│   ├── tienkung2_lite.usd              # 主 USD 文件
│   ├── config.yaml                      # USD 转换配置
│   ├── configuration/
│   │   ├── tienkung2_lite_base.usd     # 基础几何和物理
│   │   ├── tienkung2_lite_physics.usd  # 物理属性
│   │   └── tienkung2_lite_sensor.usd   # 传感器配置
│   └── .asset_hash                      # 资产哈希值
├── urdf/
│   └── tienkung2_lite.urdf             # 源 URDF 文件
├── mjcf/
│   └── tienkung.xml                     # MuJoCo XML (用于 Sim2Sim)
├── meshes/                              # 3D 网格文件
│   ├── pelvis.STL
│   ├── hip_roll_l_link.STL
│   ├── knee_pitch_l_link.STL
│   └── ... (其他 STL 文件)
└── tienkung.py                          # IsaacLab 配置文件
```

**USD 文件的层次结构**:

主文件 `tienkung2_lite.usd` 通过 **subLayers** 引用其他配置文件:
```
tienkung2_lite.usd
├── configuration/tienkung2_lite_base.usd     (几何和结构)
├── configuration/tienkung2_lite_physics.usd  (物理属性)
└── configuration/tienkung2_lite_sensor.usd   (传感器)
```

这种分层设计的优势:
- **模块化**: 不同配置分离,易于维护
- **可复用**: 可在不同场景中复用基础模型
- **版本控制**: 可单独修改物理或传感器配置

#### 🔧 USD 文件的生成

在本项目中,USD 文件是从 URDF 转换而来,配置文件 `config.yaml` 记录了转换参数:

```yaml
# 源文件
asset_path: /legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf

# 输出配置
usd_dir: /legged_lab/assets/tienkung2_lite/usd
usd_file_name: tienkung2_lite.usd
force_usd_conversion: true

# 转换选项
make_instanceable: true          # 使模型可实例化(多环境复用)
fix_base: false                  # 不固定基座(人形机器人需要自由移动)
merge_fixed_joints: true         # 合并固定关节
link_density: 0.0                # 链接密度(0表示使用URDF中的质量)

# 关节驱动配置
joint_drive:
  drive_type: force              # 力控制
  target_type: none              # 无默认目标
  gains:
    stiffness: 0.0               # 刚度(在Python配置中单独设置)
    damping: 0.0                 # 阻尼(在Python配置中单独设置)

# 碰撞配置
collider_type: convex_hull       # 使用凸包作为碰撞体
self_collision: false            # 禁用自碰撞
collision_from_visuals: false    # 不从视觉网格生成碰撞体
replace_cylinders_with_capsules: false
```

**转换工具**: IsaacSim 提供的 URDF Importer (在配置中记录为 `UrdfConverter`)

#### 🎮 USD 文件在代码中的使用

在 `legged_lab/assets/tienkung2_lite/tienkung.py:34-50`:

```python
TIENKUNG2LITE_CFG = ArticulationCfg(
    spawn=sim_utils.UsdFileCfg(
        usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
        activate_contact_sensors=True,
        rigid_props=sim_utils.RigidBodyPropertiesCfg(
            disable_gravity=False,
            max_linear_velocity=1000.0,
            max_angular_velocity=1000.0,
            ...
        ),
        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
            enabled_self_collisions=False,
            solver_position_iteration_count=8,
            solver_velocity_iteration_count=4
        ),
    ),
    ...
)
```

**关键参数说明**:
- `usd_path`: USD 文件路径
- `activate_contact_sensors`: 激活接触传感器
- `rigid_props`: 刚体物理属性(重力、速度限制等)
- `articulation_props`: 关节树属性(碰撞、求解器迭代次数)

#### 🔍 查看和编辑 USD 文件

**1. 使用 USD 工具**:
```bash
# 查看 USD 文件信息
usdcat tienkung2_lite.usd

# 转换为文本格式
usdcat tienkung2_lite.usd -o tienkung2_lite.usda

# 查看 USD 层次结构
usdtree tienkung2_lite.usd
```

**2. 使用 IsaacSim**:
- 在 IsaacSim GUI 中直接打开 USD 文件
- 可视化查看机器人模型
- 检查关节、碰撞体、物理属性

**3. 使用 USD Composer (原 Omniverse Create)**:
- Nvidia 提供的 USD 编辑器
- 可视化编辑场景、材质、物理属性

#### 🌟 USD 的优势总结

在机器人仿真中使用 USD 的优势:

1. **统一标准**: Pixar、Nvidia、Apple 等公司共同支持
2. **高性能**: 针对大规模场景优化,支持 GPU 加速
3. **场景组合**: 可以轻松组合多个机器人、环境、道具
4. **物理仿真**: 与 PhysX 等物理引擎深度集成
5. **实时渲染**: 支持光线追踪、实时渲染
6. **数据管道**: 适合从设计到仿真再到部署的完整流程

#### 相关资源

- **USD 官方文档**: https://openusd.org/
- **IsaacSim USD 文档**: https://docs.omniverse.nvidia.com/isaacsim/latest/
- **USD Python API**: `pxr` 包 (Pixar USD Python 绑定)
- **转换工具**: IsaacSim URDF Importer, USD Composer

#### 关键文件位置

- **主 USD 文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
- **转换配置**: `legged_lab/assets/tienkung2_lite/usd/config.yaml`
- **Python 配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:36`
- **源 URDF**: `legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf`
- **网格文件**: `legged_lab/assets/tienkung2_lite/meshes/*.STL`

---

## 5. play_amp_animation 的 save_path 参数详解

### 提问
play_amp_animation的save_path时要保存什么,这里保存和task以及机器人的配置文件有关吗

### 回答

#### 保存的数据内容

`play_amp_animation.py` 的 `--save_path` 参数用于保存 **AMP 专家数据**,这些数据将用于 AMP (Adversarial Motion Priors) 训练。

**数据维度组成 (共 52 维)**:

根据 `legged_lab/envs/tienkung/tienkung_env.py:336-352`,保存的数据包含:

1. **右臂关节位置** (4维): `right_arm_dof_pos`
2. **左臂关节位置** (4维): `left_arm_dof_pos`
3. **右腿关节位置** (6维): `right_leg_dof_pos`
4. **左腿关节位置** (6维): `left_leg_dof_pos`
5. **右臂关节速度** (4维): `right_arm_dof_vel`
6. **左臂关节速度** (4维): `left_arm_dof_vel`
7. **右腿关节速度** (6维): `right_leg_dof_vel`
8. **左腿关节速度** (6维): `left_leg_dof_vel`
9. **左手位置** (3维): `left_hand_pos` (相对 root 的局部坐标)
10. **右手位置** (3维): `right_hand_pos` (相对 root 的局部坐标)
11. **左脚位置** (3维): `left_foot_pos` (相对 root 的局部坐标)
12. **右脚位置** (3维): `right_foot_pos` (相对 root 的局部坐标)

**数据格式** (由 `legged_lab/scripts/play_amp_animation.py:89-113` 生成):
```json
{
"LoopMode": "Wrap",
"FrameDuration": 0.033,  // 由 --fps 参数决定 (1/fps)
"EnableCycleOffsetPosition": true,
"EnableCycleOffsetRotation": true,
"MotionWeight": 0.5,

"Frames":
[
  [关节位置(20维), 关节速度(20维), 末端位置(12维)],  // 第1帧,共52维
  [关节位置(20维), 关节速度(20维), 末端位置(12维)],  // 第2帧
  ...
]
}
```

#### 与 task 和机器人配置的关系

**是的,保存的数据与 task 和机器人配置高度相关:**

##### 1. 机器人配置文件的影响

保存的数据结构由机器人配置决定 (`legged_lab/envs/tienkung/tienkung_env.py:163-212`):

**关节映射**:
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=["hip_roll_l_joint", "hip_pitch_l_joint", "hip_yaw_l_joint",
               "knee_pitch_l_joint", "ankle_pitch_l_joint", "ankle_roll_l_joint"],
    preserve_order=True,
)
# 同理: right_leg_ids (6), left_arm_ids (4), right_arm_ids (4)
```

**Body 映射**:
```python
self.feet_body_ids, _ = self.robot.find_bodies(
    name_keys=["ankle_roll_l_link", "ankle_roll_r_link"],
    preserve_order=True
)
self.elbow_body_ids, _ = self.robot.find_bodies(
    name_keys=["elbow_pitch_l_link", "elbow_pitch_r_link"],
    preserve_order=True
)
```

**机器人模型**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
- 定义机器人的物理结构、关节名称、Body 名称
- 不同机器人的关节数量和名称不同,导致输出数据维度不同

##### 2. Task 配置的影响

**输入数据路径**在 task 配置中指定:

- **Walk Task** (`legged_lab/envs/tienkung/walk_cfg.py:164`):
  ```python
  amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/cmu_2_2_1.txt"]
  ```

- **Run Task** (`legged_lab/envs/tienkung/run_cfg.py:164`):
  ```python
  amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/run.txt"]
  ```

##### 3. 数据类型对比

**重要**: 输入的 `motion_visualization` 数据格式与输出的 AMP 专家数据格式不同:

| 数据类型 | 路径 | 维度 | 内容 |
|---------|------|------|------|
| **可视化数据** (输入) | `datasets/motion_visualization/` | 约 70 维 | `[root_pos(3), euler(3), dof_pos(26), root_lin_vel(3), root_ang_vel(3), dof_vel(26), ...]` |
| **AMP 专家数据** (输出) | `datasets/motion_amp_expert/` | 52 维 | `[dof_pos(20), dof_vel(20), end_effector_pos(12)]` |

**数据转换流程**:
```
GMR 重定向输出 (PKL)
    ↓ (gmr_data_conversion.py)
motion_visualization 数据 (TXT)  ← 包含 root 状态和完整关节信息
    ↓ (play_amp_animation.py --save_path)
motion_amp_expert 数据 (TXT)     ← 仅包含关节和末端位置,用于 AMP 训练
```

#### 使用示例

**为 TienKung 机器人生成 AMP 专家数据**:

```bash
# 从可视化数据生成 AMP 专家数据
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=walk \
    --num_envs=1 \
    --save_path legged_lab/envs/tienkung/datasets/motion_amp_expert/cmu_2_2_1.txt \
    --fps 30.0

# 查看生成的数据维度
grep "\[" legged_lab/envs/tienkung/datasets/motion_amp_expert/cmu_2_2_1.txt | head -1 | tr ',' '\n' | wc -l
# 输出应该是 52
```

**为 G1 机器人生成 AMP 专家数据** (如果机器人结构不同,输出维度可能不同):

```bash
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk \
    --num_envs=1 \
    --save_path legged_lab/envs/g1/datasets/motion_amp_expert/dance1_2.txt \
    --fps 30.0
```

#### 关键特性总结

1. **机器人特定性**:
   - 不同机器人的 AMP 数据**不能通用**
   - 关节数量、顺序、名称不同导致数据维度不同
   - Body 名称和 ID 不同影响末端位置计算

2. **输入数据要求**:
   - 必须先有对应的 `motion_visualization` 数据
   - 在配置文件中正确设置 `amp_motion_files_display` 路径

3. **数据用途**:
   - 保存的 AMP 专家数据用于训练时的判别器
   - 判别器比较策略生成的动作和专家数据的相似度
   - 在配置文件中通过 `amp_motion_files` 参数指定 (注意与 `amp_motion_files_display` 不同)

4. **FPS 参数**:
   - `--fps` 参数控制 `FrameDuration` (帧间隔时间)
   - 默认 30 FPS → FrameDuration = 0.033 秒
   - 影响动作的时间分辨率

#### 相关文件位置

- **保存逻辑**: `legged_lab/scripts/play_amp_animation.py:81-115`
- **数据生成方法**: `legged_lab/envs/tienkung/tienkung_env.py:248-352` (visualize_motion)
- **关节映射初始化**: `legged_lab/envs/tienkung/tienkung_env.py:169-212`
- **机器人配置**: `legged_lab/assets/tienkung2_lite/tienkung.py`
- **Task 配置 (输入数据)**: `legged_lab/envs/tienkung/walk_cfg.py:164` (amp_motion_files_display)
- **AMP 数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py`

---

## 6. G1 机器人关节顺序映射问题修复

### 提问
g1的重定向是没问题的,但是用play_amp_animation可视化出来是不对的,感觉是没对上,是不是哪里关节顺序不对,比如dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]这几行里的visual_motion_frame是怎么得到的,是不是g1的这里和tienkung的不一样

### 回答

#### 问题分析

经过仔细排查,发现问题出在 **G1 机器人的关节定义顺序与 GMR 输出的关节顺序不匹配**。

**关键差异**:

1. **GMR 输出的关节顺序** (来自 MuJoCo XML `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`):
   ```
   左腿 (索引 0-5):
   [0] left_hip_pitch_joint    ← pitch 在前
   [1] left_hip_roll_joint
   [2] left_hip_yaw_joint
   [3] left_knee_joint
   [4] left_ankle_pitch_joint
   [5] left_ankle_roll_joint

   右腿 (索引 6-11):
   [6] right_hip_pitch_joint   ← pitch 在前
   [7] right_hip_roll_joint
   [8] right_hip_yaw_joint
   [9] right_knee_joint
   [10] right_ankle_pitch_joint
   [11] right_ankle_roll_joint
   ```

2. **G1 环境原始定义** (`legged_lab/envs/g1/g1_env.py:158-179`):
   ```python
   self.left_leg_ids = [
       "left_hip_roll_joint",     ← roll 在前 (与 GMR 不同!)
       "left_hip_pitch_joint",
       "left_hip_yaw_joint",
       "left_knee_joint",
       "left_ankle_pitch_joint",
       "left_ankle_roll_joint",
   ]
   ```

3. **TienKung 环境定义** (`legged_lab/envs/tienkung/tienkung_env.py:169-179`):
   ```python
   self.left_leg_ids = [
       "hip_roll_l_joint",        ← roll 在前 (与 G1 原始定义一致)
       "hip_pitch_l_joint",
       "hip_yaw_l_joint",
       "knee_pitch_l_joint",
       "ankle_pitch_l_joint",
       "ankle_roll_l_joint",
   ]
   ```

**问题根源**:
- GMR 重定向工具按照 MuJoCo XML 中的树形结构顺序输出关节数据 (hip_pitch → hip_roll → hip_yaw)
- G1 环境代码按照字母顺序定义关节 (hip_roll → hip_pitch → hip_yaw)
- 在 `visualize_motion` 中直接映射 `visual_motion_frame[6:12]` 到 `self.left_leg_ids`,导致 pitch 和 roll 关节数据错位

**为什么 TienKung 没问题**:
- TienKung 使用的是自己的 URDF/XML,没有使用 GMR 的 G1 配置
- 或者 TienKung 的 GMR 配置关节顺序正好与环境代码一致

#### 解决方案

修改 `legged_lab/envs/g1/g1_env.py:158-179`,将关节定义顺序改为与 GMR 输出一致:

**修改内容** (g1_env.py:158-179):
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=[
        "left_hip_pitch_joint",  # GMR outputs pitch first
        "left_hip_roll_joint",   # 修改: 将 pitch 移到前面
        "left_hip_yaw_joint",
        "left_knee_joint",
        "left_ankle_pitch_joint",
        "left_ankle_roll_joint",
    ],
    preserve_order=True,
)
self.right_leg_ids, _ = self.robot.find_joints(
    name_keys=[
        "right_hip_pitch_joint",  # GMR outputs pitch first
        "right_hip_roll_joint",   # 修改: 将 pitch 移到前面
        "right_hip_yaw_joint",
        "right_knee_joint",
        "right_ankle_pitch_joint",
        "right_ankle_roll_joint",
    ],
    preserve_order=True,
)
```

#### 关键发现

1. **关节顺序的三个来源**:
   - **MuJoCo XML 树结构**: GMR 使用的物理模型,按照父子关系定义
   - **URDF 定义顺序**: IsaacLab 转换时可能保持或重新排序
   - **代码中的 find_joints**: 使用 `preserve_order=True` 保证按照传入顺序返回

2. **数据映射路径**:
   ```
   GMR 重定向 (MuJoCo XML顺序)
       ↓
   PKL 文件 (dof_pos: pitch, roll, yaw, ...)
       ↓ gmr_data_conversion.py (保持顺序)
   motion_visualization TXT (dof_pos[6:12]: pitch, roll, yaw, ...)
       ↓ visualize_motion
   直接映射到 self.left_leg_ids
       ⚠️ 如果顺序不匹配,会导致关节错位!
   ```

3. **验证方法**:
   运行可视化脚本检查修复效果:
   ```bash
   /home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
       --task=g1_walk --num_envs=1
   ```

#### 影响范围

**仅影响 G1 机器人**:
- ✅ TienKung 机器人不受影响 (关节顺序已匹配)
- ⚠️ 如果为 G1 训练了 AMP 策略,需要重新生成专家数据
- ⚠️ 已有的 G1 训练检查点可能需要重新训练

**不需要修改的部分**:
- ✅ `gmr_data_conversion.py` 脚本 (保持原样,按照 GMR 输出顺序)
- ✅ TienKung 环境代码 (已正确匹配)
- ✅ 数据文件 (dance1_2.txt 等)

#### 相关文件位置

- **修改文件**: `legged_lab/envs/g1/g1_env.py:158-179`
- **GMR 关节定义**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`
- **数据转换脚本**: `legged_lab/scripts/gmr_data_conversion.py` (不需要修改)
- **可视化脚本**: `legged_lab/scripts/play_amp_animation.py`
- **诊断脚本**: `legged_lab/scripts/debug_joint_order.py` (新创建,用于排查问题)

---

## 7. G1 手臂关节映射问题修复

### 提问
比之前好很多了但是还是有问题,现在左右手的动作还是明显不对的,是不是顺序或方向还是错的

### 回答

#### 进一步问题分析

经过第一次修复(腿部关节顺序),腿部动作已经正确,但手臂动作仍然不对。排查后发现**更严重的问题**:

**关键发现**: GMR 输出 29 个自由度 (包括腰部和手腕关节),但原始映射代码假设只有 26 个自由度,导致索引完全错位!

#### GMR 完整关节结构 (29 DOF)

```
[0:6]   左腿 (6 DOF): hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[6:12]  右腿 (6 DOF): hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[12:15] 腰部 (3 DOF): waist_yaw, waist_roll, waist_pitch  ← 原映射忽略了!
[15:19] 左臂 (4 DOF): shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19:22] 左手腕 (3 DOF): wrist_roll, wrist_pitch, wrist_yaw  ← 原映射忽略了!
[22:26] 右臂 (4 DOF): shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26:29] 右手腕 (3 DOF): wrist_roll, wrist_pitch, wrist_yaw  ← 原映射忽略了!
```

#### 原始错误映射

```python
# 错误的映射 (假设26 DOF,没有腰部和手腕)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]   # ❌ 实际是右腿数据!
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18] # ❌ 实际是腰部+左臂部分数据!
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]  # ❌ 实际是左手腕+右臂部分!
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26] # ❌ 实际是右臂数据(正确!)
```

这就是为什么:
- 腿部动作完全错乱 (左腿收到右腿数据)
- 左臂收到手腕数据,动作完全不对
- 只有右臂碰巧索引对了

#### visual_motion_frame 完整数据格式 (70 维)

`gmr_data_conversion.py` 输出格式:
```python
data_output = [
    root_pos[:-1],      # [0:3]   根位置
    euler_angles,       # [3:6]   欧拉角
    dof_pos[:-1],       # [6:35]  关节位置 (29 DOF)
    root_lin_vel,       # [35:38] 根线速度
    root_ang_vel,       # [38:41] 根角速度
    dof_vel             # [41:70] 关节速度 (29 DOF)
]
```

#### 正确的映射方案

```python
dof_pos_offset = 6  # skip root_pos(3) + euler(3)

# 位置数据 [6:35] (29 DOF)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # [6:12] 左腿
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # [12:18] 右腿
# [18:21] 跳过腰部 (3 DOF)
dof_pos[:, self.left_arm_ids] = visual_motion_frame[21:25]   # [21:25] 左臂
# [25:28] 跳过左手腕 (3 DOF)
dof_pos[:, self.right_arm_ids] = visual_motion_frame[28:32]  # [28:32] 右臂
# [32:35] 跳过右手腕 (3 DOF)

# 速度数据 [41:70] (29 DOF),同样的偏移
dof_vel_offset = 41  # 或 6 + 29 + 6
dof_vel[:, self.left_leg_ids] = visual_motion_frame[41:47]    # 左腿速度
dof_vel[:, self.right_leg_ids] = visual_motion_frame[47:53]   # 右腿速度
dof_vel[:, self.left_arm_ids] = visual_motion_frame[56:60]    # 左臂速度 (跳过腰部)
dof_vel[:, self.right_arm_ids] = visual_motion_frame[63:67]   # 右臂速度 (跳过左手腕)
```

#### 修改内容

**文件**: `legged_lab/envs/g1/g1_env.py:254-273`

**修改前** (部分错误已在问题6中修复):
```python
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]   # ❌ 错误!
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26]  # ❌ 错误!
```

**修改后**:
```python
# visual_motion_frame format (70 dims):
# [0:3] root_pos, [3:6] euler, [6:35] dof_pos(29), [35:38] root_lin_vel, [38:41] root_ang_vel, [41:70] dof_vel(29)
# GMR outputs 29 DOF: [legs(12) + waist(3) + left_arm(4) + left_wrist(3) + right_arm(4) + right_wrist(3)]
# G1 environment uses 20 DOF: [legs(12) + arms(8)], no waist and wrist joints

dof_pos_offset = 6  # skip root_pos(3) + euler(3)
dof_pos[:, self.left_leg_ids] = visual_motion_frame[dof_pos_offset+0:dof_pos_offset+6]    # [6:12]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[dof_pos_offset+6:dof_pos_offset+12]  # [12:18]
dof_pos[:, self.left_arm_ids] = visual_motion_frame[dof_pos_offset+15:dof_pos_offset+19]  # [21:25] (skip waist)
dof_pos[:, self.right_arm_ids] = visual_motion_frame[dof_pos_offset+22:dof_pos_offset+26] # [28:32] (skip left wrist)

# Velocity data: [41:70] (29 dims)
dof_vel_offset = 41  # 或 6 + 29 + 6
dof_vel[:, self.left_leg_ids] = visual_motion_frame[dof_vel_offset+0:dof_vel_offset+6]    # [41:47]
dof_vel[:, self.right_leg_ids] = visual_motion_frame[dof_vel_offset+6:dof_vel_offset+12]  # [47:53]
dof_vel[:, self.left_arm_ids] = visual_motion_frame[dof_vel_offset+15:dof_vel_offset+19]  # [56:60]
dof_vel[:, self.right_arm_ids] = visual_motion_frame[dof_vel_offset+22:dof_vel_offset+26] # [63:67]
```

#### 关键要点

1. **G1 环境只使用 20 个关节**:
   - 12 个腿部关节
   - 8 个手臂关节 (每臂 4 个: shoulder pitch/roll/yaw + elbow)
   - **不使用**: 腰部 3 个关节,手腕 6 个关节 (左右各 3 个)

2. **GMR 输出包含所有 29 个关节**:
   - 即使环境不使用腰部和手腕,GMR 数据中仍然包含这些关节
   - 映射时必须跳过这些不使用的关节

3. **数据验证**:
   ```bash
   # 检查 dance1_2.txt 维度
   python3 -c "
   import json
   with open('legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt') as f:
       data = json.load(f)
   print(f'Total dims: {len(data[\"Frames\"][0])}')  # 输出: 70
   "
   ```

#### 验证方法

运行可视化检查修复效果:
```bash
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1
```

现在应该能看到:
- ✅ 腿部动作正确 (问题6已修复)
- ✅ 手臂动作正确 (本次修复)
- ✅ 整体动作协调自然

#### 相关文件位置

- **修改文件**: `legged_lab/envs/g1/g1_env.py:254-273` (visualize_motion 方法)
- **关节定义**: `legged_lab/envs/g1/g1_env.py:158-207`
- **数据转换脚本**: `legged_lab/scripts/gmr_data_conversion.py` (确认输出格式)
- **诊断脚本**: `legged_lab/scripts/debug_arm_mapping.py` (新创建)
- **GMR 配置**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`

---

## 8. 在 TienKung-Lab 项目中添加新机器人完整指南

### 提问
现在是正常的,总结一下在这个项目中加一个新的机器人需要做什么,以及有什么需要注意的(如为什么之前动作不对现在对了)

### 回答

已提供完整的新机器人添加指南,包括:

#### 核心内容
1. **完整流程** (5个步骤):
   - 准备模型文件 (URDF → USD)
   - 创建环境类 (关节映射是关键!)
   - 创建任务配置
   - 注册任务
   - 动作重定向数据准备

2. **关键注意事项**:
   - ⚠️ 关节顺序必须与 GMR 输出完全一致
   - ⚠️ 处理不同机器人的 DOF 数量差异
   - ⚠️ 正确跳过不使用的关节(腰部/手腕)

3. **G1 问题根本原因**:
   - **问题 1**: 腿部 pitch/roll 顺序反了
   - **问题 2**: 手臂映射没跳过腰部/手腕关节
   - **问题 3**: 速度数据访问越界(AMPLoaderDisplay 只加载52维)

4. **修复总结**:
   - 修改关节定义顺序匹配 GMR XML
   - 修正数据映射索引,跳过不用关节
   - 将不完整的速度数据设为 0

5. **验证方法**:
   - 创建诊断脚本对比关节顺序
   - 检查数据文件维度
   - 运行可视化验证效果

#### 相关文件位置
- **修改**: `legged_lab/envs/g1/g1_env.py:158-179, 254-283`
- **参考**: GMR XML, 数据转换脚本, AMPLoaderDisplay
- **诊断**: `debug_joint_order.py`, `debug_arm_mapping.py`

---

## 9. play_amp_animation 循环播放动作

### 提问
用 legged_lab/scripts/play_amp_animation.py 机器人只会播放一次动作然后就站着不动了,怎么让他循环或者重新播放,要点哪里呢还是要改代码

### 回答

#### 问题原因

在 `legged_lab/scripts/play_amp_animation.py:77-87` 中,代码存在两个嵌套的 `while` 循环,但外层循环在播放一次动作后立即 `break` 退出,导致机器人只播放一次就停止了。

**原始代码结构** (play_amp_animation.py:77-87):
```python
frame_cnt = 0
all_frames = []
while simulation_app.is_running():    # 外层循环
    while True:                       # 内层循环
        time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
        frame = env.visualize_motion(time)
        if args_cli.save_path:
            frame = frame.cpu().numpy().reshape(-1)
            all_frames.append(frame)
        frame_cnt += 1
        if frame_cnt >= (env.motion_len - 1):
            break                     # 退出内层循环
    break                             # ❌ 退出外层循环,导致只播放一次
```

#### 解决方案

**修改内容** (play_amp_animation.py:77-86):

删除了内层 `while True` 循环和外层的 `break`,简化为单层循环:

```python
frame_cnt = 0
all_frames = []
while simulation_app.is_running():
    time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
    frame = env.visualize_motion(time)
    if args_cli.save_path:
        frame = frame.cpu().numpy().reshape(-1)
        all_frames.append(frame)
        # 如果保存模式,只播放一次
        if frame_cnt >= (env.motion_len - 1):
            break
    frame_cnt += 1
```

**关键改进**:
1. **循环播放**: 由于 `frame_cnt % (env.motion_len)` 的取模运算,动作会自动循环回到开始
2. **保存模式**: 如果指定了 `--save_path`,仍然只播放一次并保存数据
3. **可视化模式**: 没有 `--save_path` 时,动作会无限循环播放

#### 使用方法

修改后直接运行相同的命令即可循环播放:

```bash
# 循环播放 G1 跑步动作
python legged_lab/scripts/play_amp_animation.py --task=g1_run --num_envs=1

# 或使用 IsaacLab 脚本
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1
```

**操作说明**:
- 动作会自动循环播放,无需点击任何按钮
- 使用 `Ctrl+C` 或关闭窗口停止播放
- 添加 `--save_path` 参数仍然只保存一次数据

#### 相关文件位置
- **修改文件**: `legged_lab/scripts/play_amp_animation.py:77-86`

---

## 10. G1 机器人重定向动作不一致问题完整诊断

### 提问
现在运行python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1等发现g1机器人动作基本正确，但好像还是和重定向结果不一样，体现在机器人走路时摇晃而且手部摆动幅度不一致，这是因为什么，再检查一下各个关节以及数据的对齐情况和零点的对应情况

### 回答

#### 完整诊断分析

经过系统性排查,发现G1机器人走路摇晃和手臂不对称的问题有以下几个原因:

#### 1️⃣ 关节零点定义检查 ✅

**URDF vs MuJoCo XML 零点对比**:

| 关节 | URDF (IsaacLab) | MuJoCo XML (GMR) | 结论 |
|-----|----------------|------------------|-----|
| hip_roll | rpy='0 -0.1749 0' (-10.02°) | quat='0.996179 0 -0.0873386 0' (-10°) | ✅ 一致 |
| shoulder_pitch | rpy='0.27931 0 0' (16°) | quat='0.990264 0.139201 ...' (16°) | ✅ 一致 |
| shoulder_roll | rpy='-0.27925 0 0' (-16°) | quat='0.990268 -0.139172 0 0' (-16°) | ✅ 一致 |

**结论**: 零点定义一致,不是问题根源。

#### 2️⃣ 关节限位差异 ⚠️

**Left Shoulder Roll 限位对比**:
- URDF: `-1.5882 ~ 2.2515` rad (约 -91° ~ 129°)
- GMR:  `-0.6 ~ 2.2515` rad (约 -34° ~ 129°)

**影响**: URDF下限更宽松,如果GMR重定向时某些动作超出限制被截断,在IsaacLab回放时不会被截断,可能导致姿态差异。

#### 3️⃣ 关节顺序映射检查 ✅

**当前 g1_env.py 中的映射** (line 273-276):
```python
dof_pos[:, self.left_leg_ids]  = visual_motion_frame[6:12]   # GMR[0:6]
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # GMR[6:12]
dof_pos[:, self.left_arm_ids]  = visual_motion_frame[21:25]  # GMR[15:19]
dof_pos[:, self.right_arm_ids] = visual_motion_frame[28:32]  # GMR[22:26]
```

**GMR 29DOF 结构**:
```
[0:6]   左腿: hip_pitch, hip_roll, hip_yaw, knee, ankle_pitch, ankle_roll
[6:12]  右腿: 同上
[12:15] 腰部: waist_yaw, waist_roll, waist_pitch (跳过)
[15:19] 左臂: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19:22] 左手腕: wrist_roll, wrist_pitch, wrist_yaw (跳过)
[22:26] 右臂: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26:29] 右手腕: wrist_roll, wrist_pitch, wrist_yaw (跳过)
```

**结论**: 映射正确,已正确跳过腰部和手腕关节。

#### 4️⃣ 核心问题:AMPLoaderDisplay 数据截断 ⚠️⚠️⚠️

**问题确认**:
- 代码位置: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py:27-36, 73`
- 截断代码 (line 73): `motion_data[:, :AMPLoaderDisplay.JOINT_VEL_END_IDX]` → `motion_data[:, :52]`

**硬编码的常量**:
```python
JOINT_POS_SIZE = 26  # line 27
JOINT_VEL_SIZE = 26  # line 29
JOINT_VEL_END_IDX = JOINT_POSE_END_IDX + JOINT_VEL_SIZE = 26 + 26 = 52  # line 36
```

**截断详情**:
- 完整数据: 70维 = `[root(6) + dof_pos(29) + root_vel(6) + dof_vel(29)]`
- 实际读取: 52维 = `[root(6) + dof_pos(29) + root_vel(6) + dof_vel(11)]`
- **丢失数据: [52:70] = dof_vel[11:29]** (后18个DOF的速度)
  - 包括: waist速度(3) + 大部分arm速度 + 所有wrist速度

**为什么是26?**
- 原因: AMPLoaderDisplay最初为TienKung设计 (20个可控关节)
- TienKung motion文件可能是不同格式,或者26包含了其他数据
- G1有29个DOF,超出了硬编码的26限制

**当前处理** (g1_env.py:282):
```python
dof_vel[:, :] = 0.0  # Set all velocities to zero
```

**后果**:
1. 机器人回放时没有速度信息,依赖仿真器动力学计算
2. 导致动作不流畅,出现抖动和摇晃
3. 手臂摆动因速度信息缺失而不自然

#### 5️⃣ 左右对称性分析

**第一帧数据分析**:
```
Left shoulder_roll:   0.3833  |  Right:  -0.1792  (和: 0.2041)
Left shoulder_yaw:   -0.9065  |  Right:   0.2634  (和: -0.6431)
```

- `shoulder_roll`: 符号相反 ✓ (符合镜像对称)
- `shoulder_yaw`: 不是完全镜像对称 (这是行走动作的自然状态,不是静态姿态)

**结论**: 左右手臂在不同摆动相位,所以不对称是正常的。

#### 6️⃣ 综合诊断结果

**导致摇晃和手臂不对称的主要原因**:

1. ⚠️⚠️⚠️ **速度数据不完整** (主要问题)
   - AMPLoaderDisplay只读取52维,丢失后18个DOF速度
   - 当前代码将所有速度设为0,导致动作不自然

2. ⚠️ **关节限位差异**
   - GMR和URDF的关节限位不完全一致
   - 可能导致某些极限姿态的截断差异

3. ✅ **关节映射和零点已正确**
   - 关节顺序映射正确
   - 零点定义一致

#### 7️⃣ 解决方案建议

**方案1: 修复速度数据读取** (推荐)
- 修改RSL-RL库中的AMPLoaderDisplay类,读取完整70维数据
- 或在g1_env.py中直接读取motion文件

**方案2: 验证关节顺序**
```python
# 在g1_env.py:__init__中添加调试输出
print('left_leg_ids:', self.left_leg_ids)
print('left_leg_names:', [self.robot.joint_names[i] for i in self.left_leg_ids])
```
对比是否真的是 `[pitch, roll, yaw, knee, ankle_pitch, ankle_roll]`

**方案3: 检查GMR重定向质量**
- 在MuJoCo中回放GMR输出的PKL文件
- 对比MuJoCo和IsaacLab的动作差异
- 如果MuJoCo中也有问题,需要调整GMR参数

#### 8️⃣ 数据文件分析

**motion file结构** (walk1_2_start54_end61.txt):
```
维度: 70
[0:3]    root_pos
[3:6]    root_rot (euler)
[6:35]   dof_pos (29 DOF)
[35:38]  root_lin_vel
[38:41]  root_ang_vel
[41:70]  dof_vel (29 DOF)
```

**GMR关节顺序** (from MuJoCo XML):
```
[0-5]   left_leg:  pitch, roll, yaw, knee, ankle_pitch, ankle_roll
[6-11]  right_leg: pitch, roll, yaw, knee, ankle_pitch, ankle_roll
[12-14] waist:     yaw, roll, pitch (不使用)
[15-18] left_arm:  shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[19-21] left_wrist (不使用)
[22-25] right_arm: shoulder_pitch, shoulder_roll, shoulder_yaw, elbow
[26-28] right_wrist (不使用)
```

#### 相关文件位置

- **环境实现**: `legged_lab/envs/g1/g1_env.py:237-359` (visualize_motion)
- **关节定义**: `legged_lab/envs/g1/g1_env.py:158-207`
- **URDF文件**: `legged_lab/assets/g1_29dof/urdf/g1_29dof.urdf`
- **GMR XML**: `/home/ykj/project/GMR/assets/tiekunglab_g1_29dof/tiekunglab_g1_29dof.xml`
- **Motion数据**: `legged_lab/envs/g1/datasets/motion_visualization/walk1_2_start54_end61.txt`
- **数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py`

#### 下一步行动建议

1. ✅ **首要任务**: 验证find_joints()返回的实际关节顺序
2. ⚠️ **次要任务**: 修复速度数据读取问题
3. 🔍 **可选任务**: 对比MuJoCo和IsaacLab中相同关节值的姿态差异
