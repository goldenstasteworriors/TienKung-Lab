# 交互记录

## 1. 创建 CLAUDE.md 文件

### 提问
请分析这个代码库并创建一个 CLAUDE.md 文件,用于指导未来的 Claude Code 实例在此仓库中工作。

### 回答
已成功分析 TienKung-Lab 代码库并创建了 `/home/ykj/project/TienKung-Lab/CLAUDE.md` 文件。

该文件包含以下内容:

1. **项目概述**
   - TienKung-Lab 是基于 IsaacLab 的全尺寸人形机器人强化学习运动控制框架
   - 技术栈: IsaacSim 4.5.0, IsaacLab 2.1.0, RSL_RL 2.3.1, Python 3.10, MuJoCo 3.3.2

2. **常用命令**
   - 安装与设置命令
   - 训练命令 (walk/run 任务)
   - 测试与可视化命令 (带/不带传感器)
   - Sim2Sim 验证命令
   - TensorBoard 和代码格式化命令

3. **架构设计**
   - 核心组件层次结构:
     - 任务注册系统 (`task_registry.py`)
     - 基础环境架构 (`BaseEnv`, `BaseEnvCfg`)
     - TienKung 环境实现 (walk/run 配置)
     - 奖励与感知系统 (MDP 奖励、相机、激光雷达)
     - RSL-RL 算法 (PPO, AMP-PPO)

   - 动作重定向工作流:
     - 数据集结构 (`motion_visualization/`, `motion_amp_expert/`)
     - 数据转换流程 (GMR → 可视化数据 → 专家数据)

   - 关键配置参数:
     - 步态参数 (周期、离地比例、相位偏移)
     - 奖励权重
     - 仿真参数 (physics_dt: 0.005s, control freq: 50Hz)

   - 导出与部署:
     - 自动导出 JIT 和 ONNX 格式
     - 包含观察归一化器

   - 与 IsaacLab 的集成方式

4. **开发注意事项**
   - 带传感器任务的自动相机渲染
   - 策略自动导出机制
   - 日志路径结构
   - Conda 环境使用建议

文件位置: `/home/ykj/project/TienKung-Lab/CLAUDE.md`

## 2. G1 重定向效果不佳的问题排查与解决

### 提问
现在用的 g1 重定向显示出来的效果不好,现在在排查原因,我觉得可能是因为在 gmr 中我用的是 g1_mocap_29dof.xml 而在这里我用的是 g1_29dof.xml 的原因,但是 gmr 中没有 mocap 版本 xml 的 urdf 文件,这个项目在哪里要用到 urdf 文件,能不能改为使用 mocap 版本的 xml 进行 Motion Visualization 这一步,调试到可以正常执行并显示可视化界面让我检查重定向结果,用 dance1_2.txt 来可视化。

### 回答

#### 问题分析
1. **IsaacLab 使用的是 USD 文件,不是 XML**
   - 在 `legged_lab/assets/g1_29dof/g1_29dof.py:36` 中,项目使用 `g1_29dof.usd` 文件
   - XML 文件 (`g1_29dof.xml` 和 `g1_mocap_29dof.xml`) 是为 MuJoCo/GMR 准备的,不在 IsaacLab 中使用

2. **g1_29dof.xml 和 g1_mocap_29dof.xml 的主要差异**
   - **关节范围限制不同**: mocap 版本的关节范围更受限(如 hip_pitch 从 [-2.5307, 2.8798] 改为 [-1.57, 1.57])
   - **模型命名**: `g1_29dof` vs `g1_mocap`
   - **网格文件名**: 某些 link 使用了 `_rev_1_0` 后缀的网格文件
   - **额外的 body**: mocap 版本添加了 `left_toe_link` 和 `pelvis_contour_link`
   - **关节类型**: `floating_base_joint` (type="free") vs `pelvis` (freejoint)

3. **dance1_2.txt 文件位置**
   - 原始位置: `legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt`
   - 需要复制到: `legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt`

#### 解决方案

**步骤 1: 复制 dance1_2.txt 到 G1 数据集目录**
```bash
mkdir -p legged_lab/envs/g1/datasets/motion_visualization
cp legged_lab/envs/tienkung/datasets/motion_visualization/dance1_2.txt \
   legged_lab/envs/g1/datasets/motion_visualization/
```

**步骤 2: 修改 G1 环境配置**
已修改以下文件使用 dance1_2.txt:
- `legged_lab/envs/g1/g1_walk_cfg.py:164`
- `legged_lab/envs/g1/g1_run_cfg.py:164`

修改内容:
```python
amp_motion_files_display = ["legged_lab/envs/g1/datasets/motion_visualization/dance1_2.txt"]
```

**步骤 3: 验证配置**
运行测试脚本 `test_g1_dance_config.py` 确认:
- ✅ dance1_2.txt 文件存在
- ✅ JSON 格式正确
- ✅ 包含 3944 帧数据
- ✅ 每帧 70 维数据
- ✅ 两个配置文件都已更新

**步骤 4: 运行可视化**
使用以下命令运行 G1 动作可视化:
```bash
# 方式 1: 使用 IsaacLab 脚本 (推荐)
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_walk --num_envs=1

# 方式 2: 直接使用 Python (需要设置环境变量)
LD_LIBRARY_PATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni:$LD_LIBRARY_PATH \
PYTHONPATH=/home/ykj/miniconda3/envs/TieKung/lib/python3.10/site-packages/omni/kernel/py:$PYTHONPATH \
conda run -n TieKung python legged_lab/scripts/play_amp_animation.py --task=g1_walk --num_envs=1

# 方式 3: 使用 g1_run 任务
/home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
    --task=g1_run --num_envs=1
```

#### 重要发现

1. **XML vs USD 的区别**
   - IsaacSim/IsaacLab 使用 USD (Universal Scene Description) 格式
   - GMR 使用 MuJoCo XML 格式
   - 两者的差异不会影响 IsaacLab 的可视化,因为 IsaacLab 不读取 XML 文件

2. **动作数据格式**
   - `gmr_data_conversion.py` 将 GMR 输出的 PKL 文件转换为项目所需的 TXT 格式
   - 格式包含: `[root_pos(3), euler_angles(3), dof_pos(26), root_lin_vel(3), root_ang_vel(3), dof_vel(26)]`
   - G1 29DOF: 26 个可控关节 (6 腿部 × 2 + 3 腰部 + 4 手臂 × 2 + 3 手腕 × 2)

3. **可视化流程**
   - `play_amp_animation.py` 使用 `AMPLoaderDisplay` 加载 TXT 文件
   - `G1Env.visualize_motion()` 方法根据时间戳设置机器人状态
   - 数据映射: 从 TXT 格式的 dof_pos/vel 映射到 G1 的特定关节顺序

#### 下一步建议

1. **检查重定向质量**
   - 在 IsaacSim 可视化界面中观察 dance1_2 动作
   - 检查关节角度是否在合理范围内
   - 观察是否有不自然的姿态或抖动

2. **如果效果仍不理想**
   - 可能需要调整 GMR 的重定向参数
   - 检查 G1 的关节限制是否与 mocap 版本一致
   - 考虑在 `g1_29dof.py` 中调整关节范围限制

3. **生成 AMP 训练数据**
   ```bash
   /home/ykj/tool/IsaacLab/isaaclab.sh -p legged_lab/scripts/play_amp_animation.py \
       --task=g1_walk --num_envs=1 \
       --save_path legged_lab/envs/g1/datasets/motion_amp_expert/dance1_2.txt
   ```

#### 相关文件位置
- G1 USD 配置: `legged_lab/assets/g1_29dof/g1_29dof.py:36`
- G1 环境类: `legged_lab/envs/g1/g1_env.py`
- 可视化脚本: `legged_lab/scripts/play_amp_animation.py`
- 数据转换脚本: `legged_lab/scripts/gmr_data_conversion.py`
- Walk 配置: `legged_lab/envs/g1/g1_walk_cfg.py:164`
- Run 配置: `legged_lab/envs/g1/g1_run_cfg.py:164`

---

## 3. visualize_motion 实现原理

### 提问
visualize_motion这一步是怎么实现的,怎么读取的数据然后用的哪里的机器人配置文件进行可视化

### 回答

#### 整体工作流程

`visualize_motion` 是一个用于在 IsaacSim 中播放动作捕捉数据的可视化系统,主要分为以下几个步骤:

**1. 数据加载阶段 (初始化时)**

在环境初始化时 (`legged_lab/envs/tienkung/tienkung_env.py:123-126`):
```python
self.amp_loader_display = AMPLoaderDisplay(
    motion_files=self.cfg.amp_motion_files_display,
    device=self.device,
    time_between_frames=self.physics_dt
)
self.motion_len = self.amp_loader_display.trajectory_num_frames[0]
```

**2. 数据文件配置**

动作数据文件在各个任务配置中定义,例如在 `legged_lab/envs/tienkung/walk_cfg.py:164`:
```python
amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
```

**3. 数据读取与解析** (`rsl_rl/rsl_rl/utils/motion_loader_for_display.py`)

`AMPLoaderDisplay` 类负责读取和解析动作数据:
- **文件格式**: JSON 格式的 TXT 文件,包含:
  - `LoopMode`: 循环模式 ("Wrap")
  - `FrameDuration`: 帧间隔时间 (通常 1/30 秒)
  - `EnableCycleOffsetPosition/Rotation`: 循环偏移设置
  - `MotionWeight`: 动作权重
  - `Frames`: 动作帧数组

- **数据结构** (motion_loader_for_display.py:68-79):
  ```python
  motion_data = np.array(motion_json["Frames"])
  # 提取关节位置和速度数据 (前52维)
  self.trajectories_full.append(
      torch.tensor(motion_data[:, :AMPLoaderDisplay.JOINT_VEL_END_IDX], ...)
  )
  ```

- **数据维度**:
  - `JOINT_POS_SIZE = 26`: 关节位置维度
  - `JOINT_VEL_SIZE = 26`: 关节速度维度
  - 总共 52 维 (26 位置 + 26 速度)

**4. 可视化执行** (`legged_lab/scripts/play_amp_animation.py:54-87`)

主循环调用 `visualize_motion`:
```python
while simulation_app.is_running():
    while True:
        time = (frame_cnt % (env.motion_len)) * (1.0/args_cli.fps)
        frame = env.visualize_motion(time)  # 核心调用
        frame_cnt += 1
        if frame_cnt >= (env.motion_len - 1):
            break
    break
```

**5. visualize_motion 方法详解** (`legged_lab/envs/tienkung/tienkung_env.py:248-352`)

核心实现步骤:

**(1) 获取指定时间的动作帧** (248-262行):
```python
visual_motion_frame = self.amp_loader_display.get_full_frame_at_time(0, time)
```
- `get_full_frame_at_time` 方法通过线性插值获取精确时刻的动作数据
- 数据格式: `[root_pos(3), euler(3), dof_pos(26), root_lin_vel(3), ang_vel(3), dof_vel(26)]`

**(2) 映射关节数据到机器人** (265-276行):
```python
dof_pos[:, self.left_leg_ids] = visual_motion_frame[6:12]    # 左腿 6DOF
dof_pos[:, self.right_leg_ids] = visual_motion_frame[12:18]  # 右腿 6DOF
dof_pos[:, self.left_arm_ids] = visual_motion_frame[18:22]   # 左臂 4DOF
dof_pos[:, self.right_arm_ids] = visual_motion_frame[22:26]  # 右臂 4DOF
# 速度同理映射
```

**(3) 写入机器人状态** (278-302行):
```python
# 写入关节位置和速度
self.robot.write_joint_position_to_sim(dof_pos)
self.robot.write_joint_velocity_to_sim(dof_vel)

# 处理 Root 状态 (位置、姿态、速度)
root_pos = visual_motion_frame[:3].clone()
root_pos[2] += 0.3  # Z轴偏移

# Euler 角转四元数
euler = visual_motion_frame[3:6].cpu().numpy()
quat_xyzw = Rotation.from_euler("XYZ", euler, degrees=False).as_quat()
quat_wxyz = torch.tensor([quat_xyzw[3], quat_xyzw[0], quat_xyzw[1], quat_xyzw[2]], ...)

# 构建完整 root_state: [x,y,z, qw,qx,qy,qz, vx,vy,vz, wx,wy,wz]
self.robot.write_root_state_to_sim(root_state, env_ids)
```

**(4) 仿真更新** (303-305行):
```python
self.sim.render()
self.sim.step()
self.scene.update(dt=self.step_dt)
```

**(5) 计算末端执行器位置** (307-326行):
```python
# 计算左右手位置 (相对 root 的局部坐标)
left_hand_pos = self.robot.data.body_state_w[:, self.elbow_body_ids[0], :3] - ...
# 转换到 root 局部坐标系
left_hand_pos = quat_apply(quat_conjugate(self.robot.data.root_state_w[:, 3:7]), left_hand_pos)
# 同理计算脚部位置
```

**(6) 返回完整状态** (336-352行):
```python
return torch.cat((
    self.right_arm_dof_pos,   # 右臂关节位置
    self.left_arm_dof_pos,    # 左臂关节位置
    self.right_leg_dof_pos,   # 右腿关节位置
    self.left_leg_dof_pos,    # 左腿关节位置
    self.right_arm_dof_vel,   # 速度同理...
    self.left_arm_dof_vel,
    self.right_leg_dof_vel,
    self.left_leg_dof_vel,
    left_hand_pos,            # 左手位置
    right_hand_pos,           # 右手位置
    left_foot_pos,            # 左脚位置
    right_foot_pos            # 右脚位置
), dim=-1)
```

#### 机器人配置文件

**1. 主要配置文件路径**:

- **USD 模型文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
  - 在 `legged_lab/assets/tienkung2_lite/tienkung.py:36` 中引用

- **关节配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
  ```python
  TIENKUNG2LITE_CFG = ArticulationCfg(
      spawn=sim_utils.UsdFileCfg(
          usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
          ...
      ),
      init_state=ArticulationCfg.InitialStateCfg(
          pos=(0.0, 0.0, 1.0),
          joint_pos={...},  # 初始关节位置
          joint_vel={".*": 0.0},
      ),
      actuators={
          "legs": ImplicitActuatorCfg(...),   # 腿部执行器配置
          "feet": ImplicitActuatorCfg(...),   # 脚部执行器配置
          "arms": ImplicitActuatorCfg(...),   # 手臂执行器配置
      },
  )
  ```

- **环境配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
  ```python
  class TienKungWalkFlatEnvCfg:
      amp_motion_files_display = ["legged_lab/envs/tienkung/datasets/motion_visualization/walk.txt"]
      scene: BaseSceneCfg = BaseSceneCfg(
          robot=TIENKUNG2LITE_CFG,  # 使用上述机器人配置
          terrain_type="generator",
          ...
      )
  ```

**2. 关节 ID 映射** (`legged_lab/envs/tienkung/tienkung_env.py:163-212`):

系统在初始化时通过 `find_joints` 方法获取关节索引:
```python
self.left_leg_ids, _ = self.robot.find_joints(
    name_keys=["hip_roll_l_joint", "hip_pitch_l_joint", "hip_yaw_l_joint",
               "knee_pitch_l_joint", "ankle_pitch_l_joint", "ankle_roll_l_joint"],
    preserve_order=True,
)
# 同理获取 right_leg_ids, left_arm_ids, right_arm_ids, ankle_joint_ids 等
```

**3. Body ID 映射** (163-168行):
```python
self.feet_body_ids, _ = self.robot.find_bodies(
    name_keys=["ankle_roll_l_link", "ankle_roll_r_link"],
    preserve_order=True
)
self.elbow_body_ids, _ = self.robot.find_bodies(
    name_keys=["elbow_pitch_l_link", "elbow_pitch_r_link"],
    preserve_order=True
)
```

#### 数据流总结

```
1. TXT文件 (JSON格式)
   ↓ (AMPLoaderDisplay 读取)
2. Torch Tensor [N_frames, 52]
   ↓ (get_full_frame_at_time 插值)
3. 单帧数据 [root(6) + dof_pos(26) + root_vel(6) + dof_vel(26)]
   ↓ (visualize_motion 映射)
4. 机器人状态
   - dof_pos/vel → 按 joint_ids 映射到具体关节
   - root state → 写入机器人根部状态
   ↓ (IsaacSim 仿真)
5. 可视化显示 + 末端执行器位置计算
```

#### 关键文件位置汇总

- **可视化脚本**: `legged_lab/scripts/play_amp_animation.py:54-118`
- **环境实现**: `legged_lab/envs/tienkung/tienkung_env.py:248-352`
- **数据加载器**: `rsl_rl/rsl_rl/utils/motion_loader_for_display.py:26-283`
- **机器人配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:34-166`
- **任务配置**: `legged_lab/envs/tienkung/walk_cfg.py:163-184`
- **USD 模型**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`

#### 注意事项

1. **坐标系转换**:
   - Root 姿态使用欧拉角 (XYZ) 转四元数 (WXYZ)
   - 末端位置从世界坐标转换到 Root 局部坐标

2. **数据格式要求**:
   - 必须是 JSON 格式 TXT 文件
   - 包含 `FrameDuration`, `Frames` 等关键字段
   - 每帧数据至少 52 维 (26 pos + 26 vel)

3. **机器人配置一致性**:
   - USD 文件定义物理模型和视觉外观
   - ArticulationCfg 定义执行器参数
   - 关节顺序必须与数据文件匹配

---

## 4. USD 文件详解

### 提问
usd文件是什么

### 回答

#### 📚 基本概念

**USD** (Universal Scene Description,通用场景描述) 是由 **Pixar** 开发的一种开源框架和文件格式,用于描述、组合和模拟复杂的 3D 场景。

**核心特点**:
1. **通用性**: 描述完整的 3D 场景(几何、材质、灯光、相机、动画等)
2. **可组合性**: 支持场景分层和引用,可将多个 USD 文件组合
3. **高性能**: 针对大规模场景优化,支持延迟加载
4. **可扩展**: 支持自定义数据类型和属性
5. **行业标准**: 广泛应用于电影、游戏、机器人仿真等领域

#### 📁 USD 文件格式类型

| 扩展名 | 格式 | 特点 | 用途 |
|--------|------|------|------|
| `.usd` | 通用格式 | 可以是文本或二进制 | 一般用途 |
| `.usda` | ASCII 文本 | 人类可读,易于版本控制 | 调试、手动编辑 |
| `.usdc` | 二进制 Crate | 紧凑高效,加载快 | 生产环境 |
| `.usdz` | 压缩包 | 包含所有依赖资源 | 分发、AR 应用 |

在本项目中,使用的是 **`.usd` 格式**(实际为二进制 USD crate 0.8.0 版本):
```bash
$ file tienkung2_lite.usd
tienkung2_lite.usd: USD crate, version 0.8.0
```

#### 🤖 在机器人仿真中的应用

USD 文件在 IsaacSim/IsaacLab 中定义完整的机器人模型:

**1. 几何结构**:
- Links/Bodies: 机器人的刚体部件
- 网格文件引用: STL、OBJ 等格式的 3D 模型
- 视觉外观: 材质、纹理、颜色

**2. 物理属性**:
- 质量 (Mass)
- 惯性矩阵 (Inertia)
- 碰撞体 (Colliders): 凸包、网格、基本形状
- 摩擦系数、恢复系数

**3. 关节定义**:
- 关节类型: Revolute(旋转)、Prismatic(平移)、Fixed(固定)
- 关节轴向
- 关节限制 (位置、速度、力矩)
- 驱动参数 (刚度、阻尼)

**4. 传感器与附件**:
- 相机 (RGB、深度、分割)
- 激光雷达
- IMU、接触传感器等

#### 🔄 与其他格式的对比

| 格式 | 开发者 | 主要用途 | 优点 | 缺点 |
|------|--------|---------|------|------|
| **URDF** | ROS 社区 | ROS 机器人 | 简单易用,ROS 生态 | 功能有限,不支持复杂场景 |
| **MJCF/XML** | DeepMind | MuJoCo 仿真 | 物理仿真精确 | 专用格式,不通用 |
| **USD** | Pixar | 通用场景描述 | 功能强大,行业标准 | 学习曲线较陡 |
| **SDF** | OSRF | Gazebo 仿真 | 类似 URDF,功能更强 | 主要限于 Gazebo |

#### 📂 在 TienKung-Lab 项目中的使用

**项目中的 USD 文件结构**:
```
legged_lab/assets/tienkung2_lite/
├── usd/
│   ├── tienkung2_lite.usd              # 主 USD 文件
│   ├── config.yaml                      # USD 转换配置
│   ├── configuration/
│   │   ├── tienkung2_lite_base.usd     # 基础几何和物理
│   │   ├── tienkung2_lite_physics.usd  # 物理属性
│   │   └── tienkung2_lite_sensor.usd   # 传感器配置
│   └── .asset_hash                      # 资产哈希值
├── urdf/
│   └── tienkung2_lite.urdf             # 源 URDF 文件
├── mjcf/
│   └── tienkung.xml                     # MuJoCo XML (用于 Sim2Sim)
├── meshes/                              # 3D 网格文件
│   ├── pelvis.STL
│   ├── hip_roll_l_link.STL
│   ├── knee_pitch_l_link.STL
│   └── ... (其他 STL 文件)
└── tienkung.py                          # IsaacLab 配置文件
```

**USD 文件的层次结构**:

主文件 `tienkung2_lite.usd` 通过 **subLayers** 引用其他配置文件:
```
tienkung2_lite.usd
├── configuration/tienkung2_lite_base.usd     (几何和结构)
├── configuration/tienkung2_lite_physics.usd  (物理属性)
└── configuration/tienkung2_lite_sensor.usd   (传感器)
```

这种分层设计的优势:
- **模块化**: 不同配置分离,易于维护
- **可复用**: 可在不同场景中复用基础模型
- **版本控制**: 可单独修改物理或传感器配置

#### 🔧 USD 文件的生成

在本项目中,USD 文件是从 URDF 转换而来,配置文件 `config.yaml` 记录了转换参数:

```yaml
# 源文件
asset_path: /legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf

# 输出配置
usd_dir: /legged_lab/assets/tienkung2_lite/usd
usd_file_name: tienkung2_lite.usd
force_usd_conversion: true

# 转换选项
make_instanceable: true          # 使模型可实例化(多环境复用)
fix_base: false                  # 不固定基座(人形机器人需要自由移动)
merge_fixed_joints: true         # 合并固定关节
link_density: 0.0                # 链接密度(0表示使用URDF中的质量)

# 关节驱动配置
joint_drive:
  drive_type: force              # 力控制
  target_type: none              # 无默认目标
  gains:
    stiffness: 0.0               # 刚度(在Python配置中单独设置)
    damping: 0.0                 # 阻尼(在Python配置中单独设置)

# 碰撞配置
collider_type: convex_hull       # 使用凸包作为碰撞体
self_collision: false            # 禁用自碰撞
collision_from_visuals: false    # 不从视觉网格生成碰撞体
replace_cylinders_with_capsules: false
```

**转换工具**: IsaacSim 提供的 URDF Importer (在配置中记录为 `UrdfConverter`)

#### 🎮 USD 文件在代码中的使用

在 `legged_lab/assets/tienkung2_lite/tienkung.py:34-50`:

```python
TIENKUNG2LITE_CFG = ArticulationCfg(
    spawn=sim_utils.UsdFileCfg(
        usd_path=f"{ISAAC_ASSET_DIR}/tienkung2_lite/usd/tienkung2_lite.usd",
        activate_contact_sensors=True,
        rigid_props=sim_utils.RigidBodyPropertiesCfg(
            disable_gravity=False,
            max_linear_velocity=1000.0,
            max_angular_velocity=1000.0,
            ...
        ),
        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
            enabled_self_collisions=False,
            solver_position_iteration_count=8,
            solver_velocity_iteration_count=4
        ),
    ),
    ...
)
```

**关键参数说明**:
- `usd_path`: USD 文件路径
- `activate_contact_sensors`: 激活接触传感器
- `rigid_props`: 刚体物理属性(重力、速度限制等)
- `articulation_props`: 关节树属性(碰撞、求解器迭代次数)

#### 🔍 查看和编辑 USD 文件

**1. 使用 USD 工具**:
```bash
# 查看 USD 文件信息
usdcat tienkung2_lite.usd

# 转换为文本格式
usdcat tienkung2_lite.usd -o tienkung2_lite.usda

# 查看 USD 层次结构
usdtree tienkung2_lite.usd
```

**2. 使用 IsaacSim**:
- 在 IsaacSim GUI 中直接打开 USD 文件
- 可视化查看机器人模型
- 检查关节、碰撞体、物理属性

**3. 使用 USD Composer (原 Omniverse Create)**:
- Nvidia 提供的 USD 编辑器
- 可视化编辑场景、材质、物理属性

#### 🌟 USD 的优势总结

在机器人仿真中使用 USD 的优势:

1. **统一标准**: Pixar、Nvidia、Apple 等公司共同支持
2. **高性能**: 针对大规模场景优化,支持 GPU 加速
3. **场景组合**: 可以轻松组合多个机器人、环境、道具
4. **物理仿真**: 与 PhysX 等物理引擎深度集成
5. **实时渲染**: 支持光线追踪、实时渲染
6. **数据管道**: 适合从设计到仿真再到部署的完整流程

#### 相关资源

- **USD 官方文档**: https://openusd.org/
- **IsaacSim USD 文档**: https://docs.omniverse.nvidia.com/isaacsim/latest/
- **USD Python API**: `pxr` 包 (Pixar USD Python 绑定)
- **转换工具**: IsaacSim URDF Importer, USD Composer

#### 关键文件位置

- **主 USD 文件**: `legged_lab/assets/tienkung2_lite/usd/tienkung2_lite.usd`
- **转换配置**: `legged_lab/assets/tienkung2_lite/usd/config.yaml`
- **Python 配置**: `legged_lab/assets/tienkung2_lite/tienkung.py:36`
- **源 URDF**: `legged_lab/assets/tienkung2_lite/urdf/tienkung2_lite.urdf`
- **网格文件**: `legged_lab/assets/tienkung2_lite/meshes/*.STL`
